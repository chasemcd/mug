---
phase: 74-stability-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/REQUIREMENTS.md
  - .planning/STATE.md
  - .planning/ROADMAP.md
autonomous: true

must_haves:
  truths:
    - "All multi-participant tests pass (STRESS-01 through STRESS-07)"
    - "All single-participant tests pass"
    - "Zero xfail markers in test suite"
    - "Zero skip markers in test suite"
    - "Full suite passes 3 consecutive runs with zero failures"
  artifacts:
    - path: ".planning/phases/74-stability-validation/74-TEST-RESULTS.md"
      provides: "Test run catalog with pass/fail details"
      contains: "Run 1:|Run 2:|Run 3:"
  key_links:
    - from: "74-TEST-RESULTS.md"
      to: "REQUIREMENTS.md"
      via: "STAB-01 through STAB-05 status update"
      pattern: "\\[x\\] \\*\\*STAB-0[1-5]\\*\\*"
---

<objective>
Validate that the full E2E test suite passes consistently with no exemptions after Phase 73 production bug fixes.

Purpose: This is a pure validation phase. Phases 71-73 have already fixed all known issues. This phase confirms stability across the FULL test suite (not just the 8 core tests from Phase 73 verification) and documents that v1.17 E2E Test Reliability milestone is complete.

Output: Test results documentation (74-TEST-RESULTS.md), updated REQUIREMENTS.md with STAB-01 through STAB-05 marked complete, updated STATE.md and ROADMAP.md with milestone completion.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md
@.planning/phases/73-production-bug-fixes/73-VERIFICATION.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run full E2E test suite (Run 1) and catalog results</name>
  <files>.planning/phases/74-stability-validation/74-TEST-RESULTS.md</files>
  <action>
Run the full E2E test suite and document results:

1. Execute: `cd /Users/chasemcd/Repositories/interactive-gym && python -m pytest tests/e2e/ -v --tb=short 2>&1 | tee .planning/phases/74-stability-validation/run1-output.txt`
2. Scan for xfail/skip markers: `grep -r "@pytest.mark.xfail\|@pytest.mark.skip" tests/e2e/ --include="*.py"`
3. Create 74-TEST-RESULTS.md with:
   - Run 1 summary (pass/fail count, any failures with brief description)
   - xfail/skip marker audit (should be zero per Phase 73 verification)
   - Test file catalog with pass/fail status per file

If any tests FAIL:
- Document the failure details (test name, error, file)
- Note that this is a VALIDATION phase - do NOT attempt to fix
- The plan continues to Run 2 and Run 3 regardless (to document flakiness patterns)

If ALL tests PASS:
- Document "Run 1: PASSED (N/N tests)"
  </action>
  <verify>
- 74-TEST-RESULTS.md exists with Run 1 section
- run1-output.txt captured in phase directory
- xfail/skip marker count documented (expected: 0)
  </verify>
  <done>Run 1 complete and documented in 74-TEST-RESULTS.md with pass/fail breakdown</done>
</task>

<task type="auto">
  <name>Task 2: Run full E2E test suite (Run 2 and Run 3) for stability confirmation</name>
  <files>.planning/phases/74-stability-validation/74-TEST-RESULTS.md</files>
  <action>
Run the E2E test suite two more times to confirm stability (3 total runs required by STAB-05):

1. Run 2: `cd /Users/chasemcd/Repositories/interactive-gym && python -m pytest tests/e2e/ -v --tb=short 2>&1 | tee .planning/phases/74-stability-validation/run2-output.txt`
2. Run 3: `cd /Users/chasemcd/Repositories/interactive-gym && python -m pytest tests/e2e/ -v --tb=short 2>&1 | tee .planning/phases/74-stability-validation/run3-output.txt`
3. Update 74-TEST-RESULTS.md with Run 2 and Run 3 summaries

For each run, document:
- Total tests run
- Pass/fail count
- Any failures (test name, brief error)

After all 3 runs, add a summary section:
- "STABILITY CONFIRMED" if all 3 runs pass with zero failures
- "FLAKINESS DETECTED" if any run had failures, with pattern analysis

Note: Even if Run 1 had failures, complete Run 2 and Run 3 to detect flakiness patterns.
  </action>
  <verify>
- run2-output.txt and run3-output.txt captured
- 74-TEST-RESULTS.md has Run 2 and Run 3 sections
- Summary section documents overall stability status
  </verify>
  <done>3 consecutive runs completed and documented. Stability status determined.</done>
</task>

<task type="auto">
  <name>Task 3: Update REQUIREMENTS.md, STATE.md, and ROADMAP.md</name>
  <files>
    - .planning/REQUIREMENTS.md
    - .planning/STATE.md
    - .planning/ROADMAP.md
  </files>
  <action>
Update project documentation based on test results:

**If all 3 runs passed (STAB-01 through STAB-05 satisfied):**

1. REQUIREMENTS.md:
   - Change `- [ ] **STAB-01**` to `- [x] **STAB-01**` (all lines STAB-01 through STAB-05)
   - Update traceability table: STAB-01 through STAB-05 status from "Pending" to "Complete"
   - Update last updated date

2. STATE.md:
   - Update "Current focus" to "Phase 74 â€” Stability Validation (complete)"
   - Update "Phase: 74 of 74" with "Status: Complete â€” STAB-01 through STAB-05 verified"
   - Update "Progress" bar to "100% (4 of 4 phases)"
   - Add milestone to Milestone History: "v1.17 E2E Test Reliability | 71-74 | Complete | 2026-02-05"
   - Update Session Continuity: "Stopped at: v1.17 milestone complete"

3. ROADMAP.md:
   - Update "### Phase 74: Stability Validation" checkboxes to [x]
   - Update progress table row for Phase 74: "Complete" and today's date
   - Update milestone line: change `ðŸš§ **v1.17 E2E Test Reliability**` to `âœ… **v1.17 E2E Test Reliability**`
   - Move Phase 74 details into a `<details>` collapsed section like other completed phases

**If any tests failed (validation failure):**

1. Create `.planning/phases/74-stability-validation/74-FAILURE-REPORT.md` documenting:
   - Which tests failed
   - Failure patterns (same test? different tests? flaky?)
   - Recommended next steps (new phase to investigate)

2. DO NOT update REQUIREMENTS.md as complete
3. Update STATE.md with "Status: Validation failed â€” see 74-FAILURE-REPORT.md"
  </action>
  <verify>
- If passed: REQUIREMENTS.md shows [x] for STAB-01 through STAB-05
- If passed: ROADMAP.md shows Phase 74 complete
- If passed: STATE.md shows v1.17 milestone complete
- If failed: 74-FAILURE-REPORT.md exists with failure details
  </verify>
  <done>Project documentation updated to reflect validation outcome (complete or failed)</done>
</task>

</tasks>

<verification>
Phase 74 validation is complete when:

**Success path (all tests pass):**
1. `cat .planning/phases/74-stability-validation/74-TEST-RESULTS.md` shows "STABILITY CONFIRMED" with 3 passing runs
2. `grep -c "xfail\|skip" tests/e2e/*.py` returns 0 (no markers)
3. `grep "STAB-01" .planning/REQUIREMENTS.md` shows `[x]` for all STAB requirements
4. `grep "Phase 74" .planning/ROADMAP.md` shows "Complete"

**Failure path (any tests fail):**
1. 74-TEST-RESULTS.md documents all failures across 3 runs
2. 74-FAILURE-REPORT.md exists with analysis and recommendations
3. STATE.md updated with failure status
</verification>

<success_criteria>
**If validation passes:**
- All multi-participant tests pass (STRESS-01 through STRESS-07) in all 3 runs
- All single-participant tests pass in all 3 runs
- Zero xfail markers confirmed
- Zero skip markers confirmed
- Full suite passes 3 consecutive runs with zero failures
- REQUIREMENTS.md STAB-01 through STAB-05 marked complete
- v1.17 milestone marked complete in ROADMAP.md and STATE.md

**If validation fails:**
- Failure documented with pattern analysis
- No false completion claims in documentation
- Clear next steps provided
</success_criteria>

<output>
After completion, create `.planning/phases/74-stability-validation/74-01-SUMMARY.md` per summary template.
</output>
