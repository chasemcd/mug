---
phase: 47-focus-loss-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/e2e/test_data_comparison.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Test exists that simulates mid-episode focus loss and verifies data parity"
    - "Test exists that simulates focus loss near episode boundary and verifies data parity"
    - "Both tests use existing helper patterns (set_tab_visibility, wait_for_focus_manager_state)"
    - "Both tests validate export parity using run_comparison()"
  artifacts:
    - path: "tests/e2e/test_data_comparison.py"
      provides: "Focus loss data parity tests"
      contains: "test_focus_loss_mid_episode_parity"
  key_links:
    - from: "tests/e2e/test_data_comparison.py"
      to: "tests/fixtures/network_helpers.py"
      via: "set_tab_visibility import"
      pattern: "from tests.fixtures.network_helpers import.*set_tab_visibility"
    - from: "tests/e2e/test_data_comparison.py"
      to: "tests/fixtures/export_helpers.py"
      via: "run_comparison import"
      pattern: "from tests.fixtures.export_helpers import.*run_comparison"
---

<objective>
Add two focus loss data parity tests to validate FOCUS-01 and FOCUS-02 requirements.

Purpose: Verify that the dual-buffer data recording system (v1.8) maintains data parity when one player loses focus mid-episode or at episode boundary. This validates that fast-forward resync correctly records frame data.

Output: Two new test functions in tests/e2e/test_data_comparison.py that:
1. Simulate mid-episode focus loss (5 seconds hidden during gameplay)
2. Simulate focus loss near episode boundary (hide tab when close to completion)
3. Verify both players export identical data after each scenario
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@tests/e2e/test_data_comparison.py
@tests/e2e/test_network_disruption.py
@tests/fixtures/network_helpers.py
@tests/fixtures/export_helpers.py
@tests/fixtures/game_helpers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add test_focus_loss_mid_episode_parity</name>
  <files>tests/e2e/test_data_comparison.py</files>
  <action>
Add a new test function `test_focus_loss_mid_episode_parity` that validates FOCUS-01.

Implementation pattern (follow test_tab_visibility_triggers_fast_forward from test_network_disruption.py):

```python
@pytest.mark.timeout(300)
def test_focus_loss_mid_episode_parity(flask_server, player_contexts, clean_data_dir):
    """
    FOCUS-01: Test data parity maintained when one client loses focus mid-episode.

    Strategy:
    1. Run both players to active gameplay
    2. Let game run for 3 seconds (establish frames)
    3. Hide player 1's tab (simulated focus loss)
    4. Wait 5 seconds while player 2 continues
    5. Show player 1's tab (triggers fast-forward)
    6. Wait for fast-forward to complete
    7. Complete episode
    8. Compare export files for parity

    This validates that the dual-buffer data recording correctly handles:
    - Backgrounded player using defaultAction
    - Fast-forward processing buffered partner inputs
    - Data promotion after fast-forward completes
    """
```

Key implementation details:
- Use `run_full_episode_flow_until_gameplay(page1, page2, base_url)` to reach gameplay
- Use `time.sleep(3)` before hiding (let frames establish)
- Use `set_tab_visibility(page1, visible=False)` to simulate focus loss
- Use `wait_for_focus_manager_state(page1, backgrounded=True)` to verify state change
- Use `time.sleep(5)` while hidden (player 2 advances frames)
- Use `set_tab_visibility(page1, visible=True)` to trigger fast-forward
- Use `wait_for_focus_manager_state(page1, backgrounded=False)` to verify refocus
- Wait for fast-forward completion with page1.wait_for_function checking `!game._pendingFastForward`
- Use `wait_for_episode_complete` for both players
- Use `wait_for_export_files` and `run_comparison` for parity check

Import `time` at the top if not already imported.
Import `wait_for_focus_manager_state` from network_helpers (already imported as set_tab_visibility).
  </action>
  <verify>
Run: `cd /Users/chasemcd/Repositories/interactive-gym && python -c "from tests.e2e.test_data_comparison import test_focus_loss_mid_episode_parity; print('Import OK')"`
Verify import succeeds.
  </verify>
  <done>
test_focus_loss_mid_episode_parity function exists in test_data_comparison.py with correct docstring referencing FOCUS-01, uses set_tab_visibility to simulate focus loss, and uses run_comparison for parity check.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add test_focus_loss_episode_boundary_parity</name>
  <files>tests/e2e/test_data_comparison.py</files>
  <action>
Add a new test function `test_focus_loss_episode_boundary_parity` that validates FOCUS-02.

Implementation pattern:

```python
@pytest.mark.timeout(300)
def test_focus_loss_episode_boundary_parity(flask_server, player_contexts, clean_data_dir):
    """
    FOCUS-02: Test data parity maintained when one client loses focus at episode boundary.

    Strategy:
    1. Run both players to active gameplay
    2. Wait until close to episode end (frame count approaching max)
    3. Hide player 1's tab near the boundary
    4. Episode ends while player 1 is backgrounded
    5. Player 1 refocuses after episode boundary promotion occurs
    6. Compare export files for parity

    This validates that the dual-buffer data recording correctly handles:
    - _promoteRemainingAtBoundary() when player is backgrounded
    - Episode completion detection while backgrounded
    - Data consistency at episode boundaries with pending fast-forward
    """
```

Key implementation details:
- Use `run_full_episode_flow_until_gameplay(page1, page2, base_url)` to reach gameplay
- Wait for game to be ~80% through episode by checking frame count:
  ```python
  # Wait until game is close to episode end (e.g., 80% of max frames)
  # Default Overcooked episode is ~600 frames (60 seconds at 10 FPS)
  page1.wait_for_function(
      "() => window.game && window.game.frameNumber >= 480",  # 80% of 600
      timeout=120000
  )
  ```
- Then immediately hide player 1's tab
- Wait for episode complete on player 2 (player 1 may still be backgrounded when episode ends)
- Show player 1's tab after brief delay (episode should have ended)
- Use `wait_for_episode_complete` for both players (may already be complete for p2)
- Use `wait_for_export_files` and `run_comparison` for parity check

Note: Boundary timing is tricky - the test validates that episode completion works correctly even when one player is backgrounded at the moment the episode ends.
  </action>
  <verify>
Run: `cd /Users/chasemcd/Repositories/interactive-gym && python -c "from tests.e2e.test_data_comparison import test_focus_loss_episode_boundary_parity; print('Import OK')"`
Verify import succeeds.
  </verify>
  <done>
test_focus_loss_episode_boundary_parity function exists in test_data_comparison.py with correct docstring referencing FOCUS-02, waits for frame count near boundary before focus loss, and uses run_comparison for parity check.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run tests to verify they execute correctly</name>
  <files>tests/e2e/test_data_comparison.py</files>
  <action>
Run the two new tests in headed mode to verify they work:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_data_comparison.py::test_focus_loss_mid_episode_parity -v --headed --timeout=300 2>&1 | head -100

python -m pytest tests/e2e/test_data_comparison.py::test_focus_loss_episode_boundary_parity -v --headed --timeout=300 2>&1 | head -100
```

If tests fail due to timing issues or fast-forward mechanics:
- Adjust wait times or frame thresholds as needed
- Consider adding xfail marker if there are known dual-buffer edge cases (similar to test_active_input_with_packet_loss)

If tests pass, the implementation is complete.
  </action>
  <verify>
Both tests complete execution (pass or fail with actionable output).
Tests should either PASS or fail with data parity issues (not crashes or timeouts).
  </verify>
  <done>
Both tests execute to completion. If they pass: requirements FOCUS-01 and FOCUS-02 are validated. If they fail with parity issues: document the limitation similar to existing xfail tests.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. Run both new tests:
```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_data_comparison.py::test_focus_loss_mid_episode_parity tests/e2e/test_data_comparison.py::test_focus_loss_episode_boundary_parity -v --headed
```

2. Verify test structure matches existing patterns:
- Uses clean_data_dir fixture
- Uses run_full_episode_flow_until_gameplay or similar pattern
- Uses set_tab_visibility for focus simulation
- Uses wait_for_focus_manager_state for state verification
- Uses run_comparison for export parity validation

3. Check that tests are discoverable:
```bash
python -m pytest tests/e2e/test_data_comparison.py --collect-only | grep focus_loss
```
</verification>

<success_criteria>
1. test_focus_loss_mid_episode_parity exists and validates FOCUS-01
2. test_focus_loss_episode_boundary_parity exists and validates FOCUS-02
3. Both tests use existing helper patterns (set_tab_visibility, wait_for_focus_manager_state, run_comparison)
4. Both tests are discoverable by pytest
5. Tests either pass OR are marked xfail with documented reason (if dual-buffer edge cases apply)
</success_criteria>

<output>
After completion, create `.planning/phases/47-focus-loss-testing/47-01-SUMMARY.md`
</output>
