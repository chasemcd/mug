---
phase: 39-verification-metadata
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - interactive_gym/server/static/js/pyodide_multiplayer_game.js
  - scripts/validate_action_sequences.py
autonomous: true

must_haves:
  truths:
    - "Exported frame data includes wasSpeculative field for each agent"
    - "Exported data includes rollback events with frame ranges"
    - "Validation script --compare mode reports divergences between two files"
    - "Identical files report zero divergences"
  artifacts:
    - path: "interactive_gym/server/static/js/pyodide_multiplayer_game.js"
      provides: "wasSpeculative flag at promotion, rollback metadata in export"
      contains: "wasSpeculative: true"
    - path: "scripts/validate_action_sequences.py"
      provides: "Compare mode for two export files"
      contains: "--compare"
  key_links:
    - from: "_promoteConfirmedFrames()"
      to: "frameDataBuffer"
      via: "wasSpeculative flag propagation"
      pattern: "wasSpeculative.*true"
    - from: "_promoteRemainingAtBoundary()"
      to: "frameDataBuffer"
      via: "wasSpeculative flag propagation"
      pattern: "wasSpeculative.*true"
    - from: "exportEpisodeDataFromBuffer()"
      to: "export output"
      via: "includes rollback metadata"
      pattern: "rollbackEvents|sessionMetrics\\.rollbacks"
---

<objective>
Add per-frame metadata tracking and offline validation tooling for v1.8 data export parity

Purpose: Enable researchers to identify which frames were speculative predictions and compare two players' exports for divergence detection post-experiment.

Output:
- wasSpeculative.{agentId} columns in exported CSV data
- rollbackEvents in session metrics export
- `--compare file1 file2` mode in validation script
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/39-verification-metadata/39-RESEARCH.md
@.planning/phases/36-buffer-split/36-01-SUMMARY.md
@.planning/phases/38-episode-boundary/38-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add wasSpeculative flag at promotion</name>
  <files>interactive_gym/server/static/js/pyodide_multiplayer_game.js</files>
  <action>
Modify both frame promotion methods to add `wasSpeculative: true` to promoted frame data.

In `_promoteConfirmedFrames()` (around line 2966):
- When promoting frames from speculativeFrameData to frameDataBuffer
- Add `wasSpeculative: true` to the data object
- Use spread operator: `this.frameDataBuffer.set(frame, { ...data, wasSpeculative: true });`

In `_promoteRemainingAtBoundary()` (around line 2994):
- Same modification when promoting remaining frames at episode boundary
- Use spread operator: `this.frameDataBuffer.set(frame, { ...data, wasSpeculative: true });`

Note: Frames that are never speculative (direct execution without prediction) will NOT have wasSpeculative set, so undefined means it was never predicted. This is intentional - only frames that went through the speculative buffer get the flag.
  </action>
  <verify>
```bash
# Verify wasSpeculative: true appears in both promotion methods
grep -n "wasSpeculative.*true" interactive_gym/server/static/js/pyodide_multiplayer_game.js
# Should show 2 occurrences - one in each promotion method
```
  </verify>
  <done>
Both _promoteConfirmedFrames() and _promoteRemainingAtBoundary() add wasSpeculative: true to promoted frame data
  </done>
</task>

<task type="auto">
  <name>Task 2: Include rollback and wasSpeculative metadata in export</name>
  <files>interactive_gym/server/static/js/pyodide_multiplayer_game.js</files>
  <action>
Modify `exportEpisodeDataFromBuffer()` (around line 3641) to include:

1. **wasSpeculative per agent** - Add to the data object being built:
   - Initialize: `wasSpeculative: {}` in the data object (like actions, rewards, etc.)
   - In the frame loop, extract wasSpeculative from frame data and store per agent:
     ```javascript
     // Add wasSpeculative per agent (Phase 39: REC-04)
     // If frame was promoted from speculative buffer, wasSpeculative is true
     // If undefined, frame was never speculative (direct execution)
     for (const agentId of agentIds) {
         if (!data.wasSpeculative[agentId]) data.wasSpeculative[agentId] = [];
         data.wasSpeculative[agentId].push(frameData.wasSpeculative || false);
     }
     ```

2. **Rollback events metadata** - Add to the returned data object:
   - Include `rollbackEvents: this.sessionMetrics.rollbacks.events` at the end of the return object
   - This provides the full rollback history with frame ranges

The export structure will add:
- `wasSpeculative.0: [false, false, true, true, ...]` (per-agent array)
- `wasSpeculative.1: [false, false, true, true, ...]`
- `rollbackEvents: [{frame, currentFrame, rollbackFrames, playerId, ...}, ...]`
  </action>
  <verify>
```bash
# Verify wasSpeculative is in data structure and rollbackEvents is exported
grep -n "wasSpeculative" interactive_gym/server/static/js/pyodide_multiplayer_game.js | grep -v "//.*wasSpeculative"
# Should show: wasSpeculative in data object init, wasSpeculative extraction in loop

grep -n "rollbackEvents" interactive_gym/server/static/js/pyodide_multiplayer_game.js
# Should show: rollbackEvents in export return object
```
  </verify>
  <done>
exportEpisodeDataFromBuffer() includes wasSpeculative per agent and rollbackEvents from sessionMetrics
  </done>
</task>

<task type="auto">
  <name>Task 3: Add compare mode to validation script</name>
  <files>scripts/validate_action_sequences.py</files>
  <action>
Extend `scripts/validate_action_sequences.py` to add a `--compare` mode that directly compares two export files.

1. **Add CLI arguments:**
   ```python
   parser.add_argument(
       "--compare", nargs=2, metavar=("FILE1", "FILE2"),
       help="Compare two specific export files instead of scanning directory"
   )
   ```

2. **Add compare_files function:**
   ```python
   def compare_files(file1: Path, file2: Path, verbose: bool = False) -> int:
       """Compare two export files and report divergences.

       Returns exit code: 0 if identical, 1 if different.
       """
       headers1, rows1 = load_csv(file1)
       headers2, rows2 = load_csv(file2)

       errors = []

       # Check row counts
       if len(rows1) != len(rows2):
           errors.append(f"Row count mismatch: {file1.name} has {len(rows1)} rows, {file2.name} has {len(rows2)} rows")

       # Check column sets
       if set(headers1) != set(headers2):
           only_in_1 = set(headers1) - set(headers2)
           only_in_2 = set(headers2) - set(headers1)
           if only_in_1:
               errors.append(f"Columns only in {file1.name}: {only_in_1}")
           if only_in_2:
               errors.append(f"Columns only in {file2.name}: {only_in_2}")

       # Compare common columns
       common_cols = set(headers1) & set(headers2)
       min_rows = min(len(rows1), len(rows2))

       divergences = defaultdict(list)
       for i in range(min_rows):
           for col in common_cols:
               val1 = rows1[i].get(col, "")
               val2 = rows2[i].get(col, "")
               if val1 != val2:
                   divergences[col].append((i, val1, val2))

       # Report divergences
       if divergences:
           for col, diffs in sorted(divergences.items()):
               errors.append(f"Column '{col}' has {len(diffs)} divergences")
               if verbose:
                   for idx, val1, val2 in diffs[:5]:
                       errors.append(f"  Row {idx}: {file1.name}={val1}, {file2.name}={val2}")
                   if len(diffs) > 5:
                       errors.append(f"  ... and {len(diffs) - 5} more divergences")

       # Print results
       print(f"Comparing: {file1.name} vs {file2.name}")
       print("=" * 70)
       print(f"Rows: {len(rows1)} vs {len(rows2)}")
       print(f"Columns: {len(headers1)} vs {len(headers2)}")
       print()

       if errors:
           print("DIVERGENCES FOUND:")
           for error in errors:
               print(f"  {error}")
           return 1
       else:
           print("FILES ARE IDENTICAL")
           return 0
   ```

3. **Modify main() to handle compare mode:**
   At the start of main(), after argument parsing:
   ```python
   # Handle compare mode
   if args.compare:
       file1, file2 = Path(args.compare[0]), Path(args.compare[1])
       if not file1.exists():
           print(f"Error: File not found: {file1}")
           sys.exit(1)
       if not file2.exists():
           print(f"Error: File not found: {file2}")
           sys.exit(1)
       sys.exit(compare_files(file1, file2, args.verbose))
   ```
  </action>
  <verify>
```bash
# Test compare mode with same file (should report identical)
python scripts/validate_action_sequences.py --compare scripts/validate_action_sequences.py scripts/validate_action_sequences.py
echo "Exit code: $?"
# Should print "FILES ARE IDENTICAL" and exit 0

# Show help to verify --compare is documented
python scripts/validate_action_sequences.py --help | grep -A1 "compare"
```
  </verify>
  <done>
Validation script has --compare FILE1 FILE2 mode that reports divergences with exit code 0 (identical) or 1 (different)
  </done>
</task>

</tasks>

<verification>
Overall phase verification:

```bash
# 1. Verify wasSpeculative flag in both promotion methods
grep -c "wasSpeculative.*true" interactive_gym/server/static/js/pyodide_multiplayer_game.js
# Expected: 2 (one per promotion method)

# 2. Verify rollbackEvents in export
grep "rollbackEvents" interactive_gym/server/static/js/pyodide_multiplayer_game.js | head -1
# Expected: line in exportEpisodeDataFromBuffer return object

# 3. Verify compare mode works
python scripts/validate_action_sequences.py --compare scripts/validate_action_sequences.py scripts/validate_action_sequences.py && echo "PASS: identical files" || echo "FAIL"

# 4. Verify compare mode detects differences (use two different files)
python scripts/validate_action_sequences.py --compare scripts/validate_action_sequences.py README.md && echo "FAIL: should detect difference" || echo "PASS: detected difference"
```
</verification>

<success_criteria>
1. Both promotion methods add `wasSpeculative: true` to promoted frame data
2. exportEpisodeDataFromBuffer() returns wasSpeculative per agent and rollbackEvents
3. `--compare file1 file2` mode compares two files and reports divergences
4. Identical files return exit code 0, different files return exit code 1
</success_criteria>

<output>
After completion, create `.planning/phases/39-verification-metadata/39-01-SUMMARY.md` using the summary template.
</output>
