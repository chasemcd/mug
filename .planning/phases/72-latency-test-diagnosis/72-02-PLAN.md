---
phase: 72-latency-test-diagnosis
plan: 02
type: execute
wave: 2
depends_on: ["72-01"]
files_modified:
  - interactive_gym/server/static/js/pyodide_multiplayer_game.js
  - tests/e2e/test_latency_injection.py
autonomous: true

must_haves:
  truths:
    - "The 200ms latency test completes within its 300s timeout on 5 consecutive runs"
    - "The 100ms latency test continues to pass (no regression)"
    - "The fix addresses the root cause identified in Plan 01"
  artifacts:
    - path: "interactive_gym/server/static/js/pyodide_multiplayer_game.js"
      provides: "Fixed timeout or configuration addressing root cause"
    - path: "tests/e2e/test_latency_injection.py"
      provides: "Clean test without leftover diagnostic instrumentation"
  key_links:
    - from: "tests/e2e/test_latency_injection.py"
      to: "interactive_gym/server/static/js/pyodide_multiplayer_game.js"
      via: "CDP latency injection affects SocketIO signaling timing"
      pattern: "apply_latency"
---

<objective>
Fix the root cause identified in Plan 01 so that `test_episode_completion_under_fixed_latency[chromium-200]` completes reliably within its 300s timeout, then verify with 5 consecutive passes and confirm no regression on the 100ms variant.

Purpose: PERF-02 requires the 200ms latency test to complete within its timeout. The fix must address the specific root cause identified by Plan 01's diagnostic instrumentation.

Output: A targeted fix (most likely a timeout increase or timing adjustment) plus verified 5 consecutive green runs.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/72-latency-test-diagnosis/72-RESEARCH.md
@.planning/phases/72-latency-test-diagnosis/72-01-SUMMARY.md

Key source files:
@interactive_gym/server/static/js/pyodide_multiplayer_game.js
@tests/e2e/test_latency_injection.py
@tests/fixtures/game_helpers.py
@interactive_gym/server/static/js/index.js

Apply the fix based on the root cause in 72-01-SUMMARY.md. The research identified these likely fixes by hypothesis:

**If Hypothesis #1 (P2P ready gate race):**
- Increase `this.p2pReadyGate.timeoutMs` from 5000 to 15000 in `pyodide_multiplayer_game.js` (line ~1133)
- This gives SocketIO signaling more time under high latency
- 15000ms is safe: normal conditions complete in ~0.5-1s, 200ms latency in ~4-5s
- The P2P validation timeout (10000ms at line ~1142) may also need increase to 20000ms

**If Hypothesis #2 (SocketIO fallback + rollback cascade):**
- Fix is upstream: ensure P2P connects (Hypothesis #1 fix), so SocketIO fallback never triggers
- If somehow P2P can't connect under 200ms latency, the test may need to be redesigned

**If Hypothesis #3 (re-pool infinite loop):**
- Add a max re-pool attempts limit in index.js (currently unlimited via setTimeout -> join_game loop)
- Or fix the root cause (Hypothesis #1) so re-pooling never triggers

**If Hypothesis #5 (game loop never starts):**
- Ensure timer worker initialization doesn't depend on P2P gate resolution
- Or fix gate resolution (back to Hypothesis #1)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Apply root cause fix</name>
  <files>interactive_gym/server/static/js/pyodide_multiplayer_game.js, tests/e2e/test_latency_injection.py</files>
  <action>
Read 72-01-SUMMARY.md to determine the confirmed root cause, then apply the appropriate fix.

**Most likely fix (P2P ready gate timeout):**

In `pyodide_multiplayer_game.js`, increase the P2P ready gate timeout:
```javascript
// Line ~1133 (inside constructor)
this.p2pReadyGate = {
    enabled: true,
    resolved: false,
    timeoutMs: 15000,   // Was 5000 -- increased to accommodate high-latency SocketIO signaling (Phase 72)
    timeoutId: null
};
```

Also increase the P2P validation timeout to give the full validation handshake more room:
```javascript
// Line ~1142 (inside constructor)
this.p2pValidation = {
    enabled: true,
    state: 'idle',
    timeoutMs: 15000,   // Was 10000 -- increased to match ready gate (Phase 72)
    ...
};
```

The validation timeout should be <= the ready gate timeout. With both at 15000ms, validation has the full window. Under 200ms symmetric latency:
- WebRTC signaling (SDP offer/answer/ICE via SocketIO): ~2-4s
- DataChannel open + validation ping/pong: ~0.1s (DataChannel, no CDP latency)
- Server `p2p_validation_complete` via SocketIO: ~0.5-1s
- Total: ~3-5s, well within 15s

**Clean up diagnostic instrumentation:**

In `tests/e2e/test_latency_injection.py`, remove any diagnostic-only code added in Plan 01 (console capture, timing prints, polling loops) unless it adds ongoing value. The test should return to its clean state using `run_full_episode_flow`. If a small amount of timing/logging is useful for future debugging, keep it minimal and non-intrusive.

Do NOT change the test's pytest.mark.timeout(300) or the episode_timeout/setup_timeout parameters -- the fix should be in the game code, not the test timeouts.

**If the root cause was NOT Hypothesis #1:** Read 72-01-SUMMARY.md carefully and apply the fix it recommends. The action above is the most likely path but the actual fix depends on empirical diagnosis.
  </action>
  <verify>
Run the 200ms test once to confirm it passes:
```
python -m pytest tests/e2e/test_latency_injection.py::test_episode_completion_under_fixed_latency -k "200" --headed --timeout=300 -s 2>&1
```
Confirm exit code 0 and the test completes within ~60s (not close to the 300s timeout).
  </verify>
  <done>
The fix is applied and the 200ms test passes once. The test code is clean (no leftover diagnostic instrumentation beyond what's useful long-term).
  </done>
</task>

<task type="auto">
  <name>Task 2: Verify 5 consecutive passes and no regression</name>
  <files>tests/e2e/test_latency_injection.py</files>
  <action>
Run the 200ms latency test 5 consecutive times to prove stability:
```bash
for i in 1 2 3 4 5; do
  echo "=== Run $i/5 ==="
  python -m pytest tests/e2e/test_latency_injection.py::test_episode_completion_under_fixed_latency -k "200" --headed --timeout=300 -s 2>&1
  echo "Exit code: $?"
done
```

All 5 runs must pass (exit code 0). If any run fails, investigate and fix before retrying the full sequence.

Then verify the 100ms variant still passes (regression check):
```bash
python -m pytest tests/e2e/test_latency_injection.py::test_episode_completion_under_fixed_latency -k "100" --headed --timeout=300 -s 2>&1
```

This must also pass (exit code 0).

If runs are too slow to do 5 consecutive in one context window, do at least 3 consecutive and document the plan to complete the remaining runs. But 5 consecutive is the target per the phase success criteria.

NOTE: These tests are slow (2-3 minutes each). 5 runs of the 200ms test = ~10-15 minutes. Plan accordingly for the timeout. Use --timeout=300 for each individual run (not the overall loop).
  </action>
  <verify>
Output shows 5 consecutive passes for `test_episode_completion_under_fixed_latency[chromium-200]` and 1 pass for `test_episode_completion_under_fixed_latency[chromium-100]`.
  </verify>
  <done>
PERF-02 is satisfied:
1. 200ms latency test passes 5 consecutive runs (within 300s timeout each)
2. 100ms latency test still passes (no regression)
3. Phase 72 success criteria are fully met
  </done>
</task>

</tasks>

<verification>
- 200ms latency test completes in all 5 consecutive runs
- 100ms latency test passes (no regression)
- Fix is in game code (not test timeouts)
- Test file is clean of diagnostic artifacts
- The fix addresses the empirically confirmed root cause from Plan 01
</verification>

<success_criteria>
1. `test_episode_completion_under_fixed_latency[chromium-200]` passes 5 consecutive runs within 300s timeout
2. `test_episode_completion_under_fixed_latency[chromium-100]` continues to pass
3. Fix is documented in code comments referencing Phase 72
4. PERF-02 requirement satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/72-latency-test-diagnosis/72-02-SUMMARY.md`
</output>
