---
phase: 44-manual-test-protocol
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/MANUAL_TEST_PROTOCOL.md
autonomous: true

must_haves:
  truths:
    - "Researcher can follow step-by-step protocol to verify data parity"
    - "Protocol covers baseline, latency, asymmetric, jitter, packet loss, and tab focus scenarios"
    - "Protocol explains how to run validate_action_sequences.py --compare"
    - "Protocol documents expected outcomes for each test scenario"
  artifacts:
    - path: "docs/MANUAL_TEST_PROTOCOL.md"
      provides: "Step-by-step manual verification protocol"
      min_lines: 200
      contains: "validate_action_sequences.py"
  key_links:
    - from: "docs/MANUAL_TEST_PROTOCOL.md"
      to: "scripts/validate_action_sequences.py"
      via: "command line instructions"
      pattern: "validate_action_sequences\\.py --compare"
---

<objective>
Create a comprehensive manual test protocol document that researchers can follow to manually verify data parity between two players under various network conditions.

Purpose: Enable researchers to validate that both players export identical game data regardless of network conditions, using the existing validate_action_sequences.py tool.

Output: A markdown document at docs/MANUAL_TEST_PROTOCOL.md with step-by-step instructions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Validation script (the tool researchers will use)
@scripts/validate_action_sequences.py

# Test infrastructure summaries (for understanding test scenarios)
@.planning/phases/41-latency-injection/41-01-SUMMARY.md
@.planning/phases/42-network-disruption/42-01-SUMMARY.md
@.planning/phases/43-data-comparison/43-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create manual test protocol document</name>
  <files>docs/MANUAL_TEST_PROTOCOL.md</files>
  <action>
Create a comprehensive markdown document with the following structure:

# Manual Data Parity Test Protocol

## Overview
- Purpose: Verify that both players export identical game data
- When to use: Pre-deployment validation, after code changes to data recording
- Prerequisites: Two browser windows, Chrome DevTools access

## Prerequisites
- Document required setup (server running, Chrome DevTools open)
- Document how to access Chrome DevTools (F12 or Cmd+Option+I)
- Document the data directory structure (data/{scene_id}/{subject_id}_ep{N}.csv)

## Test Scenarios

### Scenario 1: Baseline (No Network Stress)
- Purpose: Confirm parity under ideal conditions
- Steps:
  1. Open two browser windows to the experiment URL
  2. Complete matchmaking and tutorial
  3. Play through one full episode
  4. Wait for episode to complete and data to export
  5. Locate export files in data/{scene_id}/ directory
  6. Run comparison command

### Scenario 2: Fixed Latency (100ms symmetric)
- Purpose: Confirm parity under moderate latency
- Steps:
  1. Open two browser windows
  2. In BOTH windows: Open DevTools > Network tab > Enable "Network throttling"
  3. Set "Slow 3G" or custom profile with 100ms latency
  4. Complete game and compare exports
- Note: Document 500ms limitation (WebRTC signaling timeouts)

### Scenario 3: Asymmetric Latency (50ms vs 200ms)
- Purpose: Confirm parity when players have different latencies
- Steps:
  1. Open two browser windows
  2. Player 1: Set 50ms latency in DevTools
  3. Player 2: Set 200ms latency in DevTools
  4. Complete game and compare exports

### Scenario 4: Variable Latency (Jitter)
- Purpose: Confirm parity under fluctuating latency
- Steps:
  1. Manual method: Toggle between network presets during gameplay
  2. Or use "Offline" momentarily then restore
  3. Complete game and compare exports

### Scenario 5: Packet Loss
- Purpose: Confirm parity after rollback scenarios
- Steps:
  1. Open two browser windows
  2. In DevTools > Network Conditions: Set "Offline" briefly (1-2 seconds) during gameplay
  3. This triggers P2P reconnection and potential rollbacks
  4. Complete game and compare exports
- Expected: Rollback events in export (check wasSpeculative column)

### Scenario 6: Tab Focus Loss
- Purpose: Confirm parity after fast-forward resync
- Steps:
  1. Start a game between two browser windows
  2. During gameplay, click outside one browser window (defocus)
  3. Wait 5 seconds
  4. Click back to the game window
  5. Complete episode and compare exports
- Expected: One player will have fast-forwarded to catch up

## Running Comparisons

### Using validate_action_sequences.py

Document the command syntax and output interpretation:

```bash
# Compare two specific export files
python scripts/validate_action_sequences.py --compare data/{scene}/player1_ep1.csv data/{scene}/player2_ep1.csv

# Verbose mode for detailed divergence info
python scripts/validate_action_sequences.py --compare file1.csv file2.csv --verbose
```

### Interpreting Results

- Exit code 0: FILES ARE IDENTICAL (pass)
- Exit code 1: DIVERGENCES FOUND (fail)
- Document what columns are compared (actions, rewards, terminateds, truncateds, t, episode_num)
- Document wasSpeculative column meaning

## Expected Outcomes

Create a table mapping each scenario to expected outcomes:

| Scenario | Expected Comparison Result | Notes |
|----------|---------------------------|-------|
| Baseline | IDENTICAL | No stress, should always pass |
| 100ms Latency | IDENTICAL | Dual-buffer handles confirmation delay |
| Asymmetric | IDENTICAL | GGPO rollback handles mispredictions |
| Jitter | IDENTICAL | Variable latency is normal operation |
| Packet Loss | IDENTICAL | Rollbacks are corrected before export |
| Tab Focus | IDENTICAL | Fast-forward catches up before export |

Document that ALL scenarios should result in IDENTICAL exports if the system is working correctly. Any divergence indicates a bug.

## Troubleshooting

### Common Issues
- "Files not found" - Wait longer, check data directory path
- "Row count mismatch" - Episode may not have completed for both players
- "Column divergences in actions" - Potential bug in dual-buffer or rollback handling

### Collecting Debug Information
- Browser console logs (filter for "ROLLBACK", "FAST_FORWARD", "CONFIRMED")
- Export files contain wasSpeculative and rollbackEvents columns for debugging
  </action>
  <verify>
- File exists: `ls -la docs/MANUAL_TEST_PROTOCOL.md`
- File has comprehensive content: `wc -l docs/MANUAL_TEST_PROTOCOL.md` (should be 200+ lines)
- Markdown syntax valid: `head -50 docs/MANUAL_TEST_PROTOCOL.md`
- References validate_action_sequences.py: `grep -c "validate_action_sequences" docs/MANUAL_TEST_PROTOCOL.md` (should be > 0)
  </verify>
  <done>
Document exists with:
- 6 test scenarios fully documented (baseline, fixed latency, asymmetric, jitter, packet loss, tab focus)
- Clear step-by-step instructions for each scenario
- validate_action_sequences.py command examples
- Expected outcomes table
- Troubleshooting section
  </done>
</task>

</tasks>

<verification>
1. Document exists at docs/MANUAL_TEST_PROTOCOL.md
2. Document is at least 200 lines (comprehensive coverage)
3. All 6 network scenarios are documented
4. validate_action_sequences.py --compare command is documented
5. Expected outcomes table is present
6. Troubleshooting section exists
</verification>

<success_criteria>
- [ ] docs/MANUAL_TEST_PROTOCOL.md exists
- [ ] Document covers all 6 network condition scenarios from Phases 41-42
- [ ] Document includes step-by-step instructions for each scenario
- [ ] Document explains how to use validate_action_sequences.py --compare
- [ ] Document includes expected outcomes for each test
- [ ] Requirement DOC-01 is satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/44-manual-test-protocol/44-01-SUMMARY.md`
</output>
