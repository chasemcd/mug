---
phase: 73-production-bug-fixes
plan: 02
type: execute
wave: 1
depends_on: ["73-01"]
files_modified:
  - interactive_gym/server/static/js/pyodide_multiplayer_game.js
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "test_active_input_with_latency[100] passes with zero divergences"
    - "Both peers terminate episodes at exactly the same row (max_steps rows exported)"
    - "All previously-passing parity tests continue to pass (idle, latency, packet loss, focus loss)"
    - "Rollback mechanism still functions correctly under normal and high-frequency rollback scenarios"
  artifacts:
    - path: "interactive_gym/server/static/js/pyodide_multiplayer_game.js"
      provides: "Fixed step_num accounting during rollback replay and snapshot updates"
      contains: "restoredStepNum"
  key_links:
    - from: "performRollback() snapshot update loop"
      to: "snapshotData.step_num"
      via: "per-frame step_num calculation based on offset from target frame"
      pattern: "restoredStepNum.*frame.*targetFrame"
    - from: "loadStateSnapshot()"
      to: "this.step_num"
      via: "snapshot restore sets step_num from saved value"
      pattern: "this\\.step_num = snapshotData\\.step_num"
    - from: "step_num >= max_steps"
      to: "episode termination"
      via: "episode end detection in main tick"
      pattern: "step_num >= this\\.max_steps"
---

<objective>
Fix step_num double-counting during rollback replay that causes episode boundary divergence between peers under high rollback frequency.

Purpose: The last remaining gap from Phase 73 verification — `test_active_input_with_latency[100]` fails with ~20 divergences at the episode boundary because peers terminate at different rows (e.g., 466 vs 460 instead of both at 450). The root cause is that snapshots saved during rollback replay store the wrong step_num value, which compounds across cascading rollbacks to inflate step_num.

Output: Fixed `performRollback()` in `pyodide_multiplayer_game.js` where snapshots saved during replay store the correct per-frame step_num, and the post-replay step_num calculation is explicit and correct.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/73-production-bug-fixes/73-01-SUMMARY.md
@.planning/phases/73-production-bug-fixes/73-VERIFICATION.md
@interactive_gym/server/static/js/pyodide_multiplayer_game.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix step_num accounting in performRollback() snapshot updates</name>
  <files>interactive_gym/server/static/js/pyodide_multiplayer_game.js</files>
  <action>
Fix the step_num accounting bug in `performRollback()` that causes episode boundary divergence between peers.

**The Bug (traced precisely):**

During rollback replay, snapshots are updated at line 4667 with `snapshotData.step_num = this.step_num`. But at this point `this.step_num` is still the value restored from the rollback target snapshot (line 4360), NOT the correct step_num for each snapshot's frame. Later, `this.step_num += replayLog.length` (line 4686) fixes the final value but the intermediate snapshots are already saved with the wrong step_num.

Example of how this compounds:
1. Normal play to frame 110, step_num=110
2. Rollback to frame 100 (snapshot restores step_num=100)
3. Replay 100->110: snapshot at frame 105 saved with step_num=100 (WRONG, should be 105)
4. step_num += 10 = 110 (final value correct)
5. Later rollback to frame 105: restores step_num=100 from the bad snapshot
6. Replay 105->115: step_num = 100 + 10 = 110 (WRONG, should be 115)
7. step_num is now 5 behind, causing late episode termination on this peer

The peer with fewer cascading rollbacks has a more accurate step_num, so it terminates at the right time while the other peer overshoots.

**The Fix:**

In `performRollback()`, make two changes:

**Change A: Save correct per-frame step_num in replay snapshots**

Capture the restored step_num and the snapshot frame number BEFORE the replay loop. Then in the snapshot update loop (currently around line 4663-4670), calculate the correct step_num for each frame based on its offset from the snapshot frame:

Find the snapshot update loop:
```javascript
// Update snapshots with corrected state from replay
for (const [frameStr, snapshotData] of Object.entries(snapshotsToSave)) {
    const frame = parseInt(frameStr);
    snapshotData.cumulative_rewards = {...this.cumulative_rewards};
    snapshotData.step_num = this.step_num;
    this.stateSnapshots.set(frame, JSON.stringify(snapshotData));
    p2pLog.debug(`SNAPSHOT_UPDATED: frame=${frame} (corrected after rollback)`);
}
```

Replace it with:
```javascript
// Update snapshots with corrected state from replay
// CRITICAL: Each snapshot must store the correct step_num for its frame.
// step_num tracks how many env.step() calls have happened since episode start.
// During normal play, snapshot at frame F stores step_num = F (step_num starts at 0,
// incremented after each step, snapshot saved before stepping).
// After rollback, the restored step_num = restoredStepNum (from target snapshot).
// Each replayed frame advances step_num by 1, so snapshot at frame F should have:
//   step_num = restoredStepNum + (F - snapshotFrame)
// where snapshotFrame is the frame we loaded the snapshot from.
for (const [frameStr, snapshotData] of Object.entries(snapshotsToSave)) {
    const frame = parseInt(frameStr);
    snapshotData.cumulative_rewards = {...this.cumulative_rewards};
    snapshotData.step_num = restoredStepNum + (frame - snapshotFrame);
    this.stateSnapshots.set(frame, JSON.stringify(snapshotData));
    p2pLog.debug(`SNAPSHOT_UPDATED: frame=${frame} step_num=${snapshotData.step_num} (corrected after rollback)`);
}
```

To make this work, you need `restoredStepNum` and `snapshotFrame` to be available. `snapshotFrame` is already a local variable (line 4435). For `restoredStepNum`, capture it right after `loadStateSnapshot()` succeeds:

After line 4449 (`if (!loaded) { return false; }`), add:
```javascript
// Capture restored step_num for snapshot correction later
const restoredStepNum = this.step_num;
```

**Change B: Make post-replay step_num explicit**

Replace line 4686:
```javascript
this.step_num += replayLog.length;
```

With an explicit calculation that makes the intent clear and avoids depending on the current value of step_num:
```javascript
// Set step_num to match what it should be after replaying all frames.
// restoredStepNum is the step_num at snapshotFrame (before any replay steps).
// We replayed from snapshotFrame to currentFrame, so total steps = currentFrame - snapshotFrame.
this.step_num = restoredStepNum + replayLog.length;
```

This is mathematically equivalent to `this.step_num += replayLog.length` when step_num hasn't been modified during replay, but makes the calculation explicit and traceable. The key difference is that Change A now saves correct per-frame values in snapshots, so subsequent rollbacks won't compound errors.

**What NOT to change:**
- Do NOT modify `saveStateSnapshot()` (line 4275-4298) — normal save path is correct
- Do NOT modify `loadStateSnapshot()` (line 4330-4367) — restore path is correct
- Do NOT modify `stepWithActions()` step_num++ (line 2619) — normal increment is correct
- Do NOT modify `_performFastForward()` step_num += (line 4946) — fast-forward is a different path
- Do NOT modify the episode termination check (line 2409) — `step_num >= max_steps` is the correct check
- Do NOT change the `snapshotsToSave` accumulation during replay (lines 4614-4617) — that code is correct
- Do NOT change the batch operations or replay frame construction — the Worker batch is correct

**Why this fix is correct:**
- Normal play: snapshot at frame F saves step_num = F (unchanged, this path is correct)
- After rollback from frame C to snapshot at frame S (step_num=S in snapshot):
  - Snapshot at frame F (during replay): step_num = S + (F - S) = F (correct!)
  - Final step_num after replay: S + (C - S) = C (correct!)
  - Subsequent rollback to frame F: restores step_num = F (correct!)
  - No compounding error regardless of number of cascading rollbacks
  </action>
  <verify>
Read `performRollback()` in `pyodide_multiplayer_game.js` and verify:

1. `restoredStepNum` is captured immediately after `loadStateSnapshot()` succeeds (after the `if (!loaded)` check)
2. The snapshot update loop uses `restoredStepNum + (frame - snapshotFrame)` instead of `this.step_num`
3. The snapshot update debug log includes the step_num value
4. The post-replay step_num assignment is `this.step_num = restoredStepNum + replayLog.length` (not `+=`)
5. No other step_num-related code was modified (search for `step_num` in the file to confirm)
6. The `saveStateSnapshot()`, `loadStateSnapshot()`, `stepWithActions()`, and `_performFastForward()` methods are unchanged
  </verify>
  <done>performRollback() saves correct per-frame step_num in replay snapshots using `restoredStepNum + (frame - snapshotFrame)`, and uses explicit `this.step_num = restoredStepNum + replayLog.length` for post-replay step_num. No compounding error across cascading rollbacks.</done>
</task>

<task type="auto">
  <name>Task 2: Verify fix with E2E tests</name>
  <files>interactive_gym/server/static/js/pyodide_multiplayer_game.js</files>
  <action>
Run the previously-failing latency test to verify the step_num fix resolves the episode boundary divergence:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_latency_injection.py::test_active_input_with_latency[100] -xvs 2>&1 | tail -80
```

This test previously failed with ~20 divergences at episode boundary rows (455+, where max_steps=450). With the fix, both peers should terminate at exactly the same row and export exactly max_steps rows of data.

**Expected result:** PASSED with 0 divergences.

If it passes, run the full set of target + regression tests to confirm no regressions:

```bash
python -m pytest tests/e2e/test_data_comparison.py::test_active_input_parity tests/e2e/test_data_comparison.py::test_export_parity_basic tests/e2e/test_data_comparison.py::test_export_parity_with_latency tests/e2e/test_data_comparison.py::test_focus_loss_mid_episode_parity tests/e2e/test_latency_injection.py::test_active_input_with_latency[100] tests/e2e/test_latency_injection.py::test_episode_completion_under_fixed_latency[100] tests/e2e/test_network_disruption.py::test_active_input_with_packet_loss tests/e2e/test_network_disruption.py::test_packet_loss_triggers_rollback -xvs 2>&1 | tail -120
```

**Expected result:** All 8 tests PASSED.

**If the latency test still fails:**

1. Check whether the divergences are still at episode boundary rows (455+). If they moved to different rows, the fix changed behavior but didn't fully resolve it.

2. Add diagnostic logging temporarily to verify snapshot step_num values:
   - In the snapshot update loop, the debug log should now show the correct step_num for each frame
   - Check for patterns like `SNAPSHOT_UPDATED: frame=105 step_num=105` (correct) vs `step_num=100` (still broken)

3. If divergences are within the episode body (not boundary), this is a different issue from step_num inflation and needs separate investigation.

4. If both peers export the same number of rows but different data at boundary, the issue is not step_num but rather what data gets stored during rollback near the boundary.

**Timeout guidance:** The latency test takes 60-120 seconds. The full 8-test suite may take 8-15 minutes. Use `--timeout=300` if individual tests timeout.
  </action>
  <verify>
All 8 E2E tests pass:

Target tests (previously failing):
- `test_active_input_parity` -- PASSED (was fixed in 73-01, should still pass)
- `test_active_input_with_latency[100]` -- PASSED (was failing with ~20 divergences, now 0)
- `test_active_input_with_packet_loss` -- PASSED (was fixed in 73-01, should still pass)

Regression tests (must continue passing):
- `test_export_parity_basic` -- PASSED
- `test_export_parity_with_latency` -- PASSED
- `test_focus_loss_mid_episode_parity` -- PASSED
- `test_episode_completion_under_fixed_latency[100]` -- PASSED
- `test_packet_loss_triggers_rollback` -- PASSED
  </verify>
  <done>All 8 E2E tests pass with zero divergences. The step_num accounting fix resolves the episode boundary divergence under high rollback frequency. Both peers now terminate episodes at exactly the same row.</done>
</task>

</tasks>

<verification>
1. `test_active_input_with_latency[100]` passes with 0 divergences (was ~20 divergences at episode boundary)
2. Both peers export exactly max_steps (450) rows of data
3. `test_active_input_parity` still passes with 0 divergences
4. `test_active_input_with_packet_loss` still passes with 0 divergences
5. All 5 regression tests continue to pass
6. Snapshot step_num values during rollback replay are mathematically correct (frame-based, not accumulated)
</verification>

<success_criteria>
- Zero data parity divergences in test_active_input_with_latency[100] (previously ~20 divergences)
- Zero regressions in all 7 other parity/rollback tests
- 5/5 must-have truths from Phase 73 now verified (was 4/5)
- PROD-01 and PROD-02 requirements fully satisfied (3/3 target tests pass)
</success_criteria>

<output>
After completion, create `.planning/phases/73-production-bug-fixes/73-02-SUMMARY.md`
</output>
