---
phase: 46-test-suite-verification
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/e2e/test_infrastructure.py
  - tests/e2e/test_multiplayer_basic.py
  - tests/e2e/test_latency_injection.py
  - tests/e2e/test_network_disruption.py
  - tests/e2e/test_data_comparison.py
  - tests/fixtures/game_helpers.py
  - tests/fixtures/network_helpers.py
  - tests/fixtures/export_helpers.py
autonomous: true

must_haves:
  truths:
    - "test_infrastructure.py smoke tests pass (1 test)"
    - "test_multiplayer_basic.py matchmaking and episode tests pass (2 tests)"
    - "test_latency_injection.py latency scenarios pass (5 tests: 100ms, 200ms, asymmetric, jitter, active input)"
    - "test_network_disruption.py packet loss and focus tests pass (3 tests)"
    - "test_data_comparison.py parity validation tests pass (3 tests)"
  artifacts:
    - path: ".planning/phases/46-test-suite-verification/46-01-SUMMARY.md"
      provides: "Test verification results and any fixes applied"
  key_links:
    - from: "tests/fixtures/network_helpers.py"
      to: "set_tab_visibility"
      via: "import in all E2E test files"
      pattern: "set_tab_visibility.*visible=True"
    - from: "tests/fixtures/game_helpers.py"
      to: "run_full_episode_flow_until_gameplay"
      via: "shared helper used by latency/disruption/comparison tests"
      pattern: "run_full_episode_flow_until_gameplay"
---

<objective>
Run all E2E tests to verify the visibility fix from Phase 45 enables test passage, and fix any remaining issues discovered during test execution.

Purpose: Validate that SYNC-01 through SYNC-04 and TEST-01 through TEST-05 requirements are satisfied by running the complete E2E test suite.

Output: All 14 E2E tests pass in headed mode. Any issues discovered are diagnosed and fixed.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/45-episode-completion-fix/45-01-SUMMARY.md

# Test files to run
@tests/e2e/test_infrastructure.py
@tests/e2e/test_multiplayer_basic.py
@tests/e2e/test_latency_injection.py
@tests/e2e/test_network_disruption.py
@tests/e2e/test_data_comparison.py

# Test fixtures (may need fixes)
@tests/fixtures/game_helpers.py
@tests/fixtures/network_helpers.py
@tests/fixtures/export_helpers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run infrastructure and basic multiplayer tests</name>
  <files>tests/e2e/test_infrastructure.py, tests/e2e/test_multiplayer_basic.py</files>
  <action>
Run the smoke and basic multiplayer tests first to verify the core infrastructure works:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_infrastructure.py tests/e2e/test_multiplayer_basic.py -v --headed 2>&1
```

Expected tests (3 total):
- test_server_starts_and_contexts_connect (infrastructure smoke)
- test_matchmaking_pairs_two_players (basic matchmaking)
- test_two_players_connect_and_complete_episode (full episode)

If tests PASS: Record results and move to Task 2.

If tests FAIL: Diagnose the issue:
1. Check error message for root cause
2. Look for timeout issues, assertion failures, or connection problems
3. If the issue is in test code or fixtures, fix it
4. If the issue is in game code, document it and continue

Common issues to check:
- Visibility override missing (should be fixed by Phase 45)
- Tutorial scene calls still present (should be fixed by Phase 45)
- Socket connection timeouts (may need increased timeout)
- Game object not found (may need longer wait)
  </action>
  <verify>
Tests pass:
- test_server_starts_and_contexts_connect: PASSED
- test_matchmaking_pairs_two_players: PASSED
- test_two_players_connect_and_complete_episode: PASSED

Or failures are documented with root cause identified.
  </verify>
  <done>
3/3 basic tests pass, or failures are documented with clear diagnosis.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run latency injection tests</name>
  <files>tests/e2e/test_latency_injection.py</files>
  <action>
Run the latency injection tests to verify game behavior under network stress:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_latency_injection.py -v --headed 2>&1
```

Expected tests (5 total):
- test_episode_completion_under_fixed_latency[100] (100ms symmetric)
- test_episode_completion_under_fixed_latency[200] (200ms symmetric)
- test_episode_completion_under_asymmetric_latency (50ms vs 200ms)
- test_episode_completion_under_jitter (100ms +/- 75ms)
- test_active_input_with_latency[100] (active input + 100ms)
- test_active_input_with_latency[200] (active input + 200ms)

NOTE: These tests are slow (~2-3 min each due to episode timeouts).

If tests PASS: Record results and move to Task 3.

If tests FAIL: Diagnose the issue:
1. Check if it's a CDP session issue (latency injection problem)
2. Check if it's a data parity issue (export comparison failing)
3. Check if it's a timeout issue (episode not completing)

The visibility fix from Phase 45 should enable frame advancement. If episodes still timeout, check:
- FocusManager.isBackgrounded() returns false after set_tab_visibility(True)
- frameNumber is incrementing in game state
  </action>
  <verify>
Tests pass:
- test_episode_completion_under_fixed_latency[100]: PASSED
- test_episode_completion_under_fixed_latency[200]: PASSED
- test_episode_completion_under_asymmetric_latency: PASSED
- test_episode_completion_under_jitter: PASSED
- test_active_input_with_latency[100]: PASSED
- test_active_input_with_latency[200]: PASSED

Or failures are documented with root cause identified.
  </verify>
  <done>
5/5 latency tests pass (parametrized tests count as one), or failures are documented with clear diagnosis.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run network disruption and data comparison tests</name>
  <files>tests/e2e/test_network_disruption.py, tests/e2e/test_data_comparison.py</files>
  <action>
Run the network disruption tests (rollback, fast-forward) and data comparison tests:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/test_network_disruption.py tests/e2e/test_data_comparison.py -v --headed 2>&1
```

Expected tests (6 total):
Network disruption (3):
- test_packet_loss_triggers_rollback (15% packet loss)
- test_tab_visibility_triggers_fast_forward (tab hide/show)
- test_active_input_with_packet_loss (active input + packet loss)

Data comparison (3):
- test_export_parity_basic (no stress)
- test_export_parity_with_latency (100ms latency)
- test_active_input_parity (active inputs)

If tests PASS: Record all results and summarize.

If tests FAIL: Diagnose the issue:
1. For packet loss test: Check rollback stats are being captured
2. For tab visibility test: Check fast-forward triggers correctly
3. For data comparison tests: Check export files are written and match

If data parity fails (exit code != 0), this indicates a bug in v1.8 data recording:
- Check for row count mismatch (SYNC-01 violation)
- Check for column value mismatch (action/observation divergence)
- Run validate_action_sequences.py --compare manually for detailed output
  </action>
  <verify>
Tests pass:
- test_packet_loss_triggers_rollback: PASSED
- test_tab_visibility_triggers_fast_forward: PASSED
- test_active_input_with_packet_loss: PASSED
- test_export_parity_basic: PASSED
- test_export_parity_with_latency: PASSED
- test_active_input_parity: PASSED

Or failures are documented with root cause identified.
  </verify>
  <done>
6/6 disruption and comparison tests pass, or failures are documented with clear diagnosis.
  </done>
</task>

</tasks>

<verification>
After all tasks complete, verify the full test suite:

```bash
cd /Users/chasemcd/Repositories/interactive-gym
python -m pytest tests/e2e/ -v --headed 2>&1 | tail -50
```

Expected output summary:
```
14 passed in Xm Xs
```

Or partial passes with documented failures.

Requirement verification:
- TEST-01: test_infrastructure.py passes (1/1)
- TEST-02: test_multiplayer_basic.py passes (2/2)
- TEST-03: test_latency_injection.py passes (5/5)
- TEST-04: test_network_disruption.py passes (3/3)
- TEST-05: test_data_comparison.py passes (3/3)
- SYNC-01 through SYNC-04: Verified via data comparison tests
</verification>

<success_criteria>
All 14 E2E tests pass in headed mode:
- [ ] test_infrastructure.py: 1 test passes
- [ ] test_multiplayer_basic.py: 2 tests pass
- [ ] test_latency_injection.py: 5 tests pass (3 parametrized)
- [ ] test_network_disruption.py: 3 tests pass
- [ ] test_data_comparison.py: 3 tests pass

If any tests fail:
- [ ] Root cause identified and documented
- [ ] Fixes applied to test code or fixtures (if applicable)
- [ ] Known limitations documented (if game code changes needed)
</success_criteria>

<output>
After completion, create `.planning/phases/46-test-suite-verification/46-01-SUMMARY.md` with:
- Test execution results for each test file
- Any fixes applied during execution
- Failures diagnosed with root cause
- Requirements verified (TEST-01 through TEST-05, SYNC-01 through SYNC-04)
</output>
