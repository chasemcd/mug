---
phase: 65-multi-episode-lifecycle-stress-tests
plan: 02
type: execute
wave: 2
depends_on: ["65-01"]
files_modified:
  - tests/e2e/test_lifecycle_stress.py
  - tests/fixtures/multi_participant.py
autonomous: true

must_haves:
  truths:
    - "Participant can complete 2 episodes back-to-back without state corruption (STRESS-02)"
    - "Mid-game disconnect shows overlay to partner and exports data (STRESS-03)"
    - "Waiting room disconnect does not affect other participants (STRESS-04)"
    - "Focus loss triggers game end after timeout (STRESS-05)"
    - "Mixed lifecycle scenarios complete without server state corruption (STRESS-06)"
    - "All completed games pass exact parity validation (STRESS-07)"
  artifacts:
    - path: "tests/e2e/test_lifecycle_stress.py"
      provides: "Stress test implementations for STRESS-02 through STRESS-07"
      min_lines: 200
    - path: "tests/fixtures/multi_participant.py"
      provides: "Extended GameOrchestrator with multi-episode support"
      contains: "wait_for_all_episodes_complete"
  key_links:
    - from: "tests/e2e/test_lifecycle_stress.py"
      to: "tests/fixtures/multi_participant.py"
      via: "GameOrchestrator import"
      pattern: "from tests.fixtures.multi_participant import GameOrchestrator"
    - from: "tests/e2e/test_lifecycle_stress.py"
      to: "tests/conftest.py"
      via: "fixture parameters"
      pattern: "flask_server_multi_episode|flask_server_focus_timeout"
---

<objective>
Create comprehensive stress tests for all participant lifecycle scenarios.

Purpose: Validate that the system handles multi-episode games, disconnections, and focus loss correctly. These tests build on Phase 64's multi-participant infrastructure to verify STRESS-02 through STRESS-07 requirements.

Output: `test_lifecycle_stress.py` with 5 test functions covering all lifecycle scenarios, plus any needed GameOrchestrator enhancements.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/65-multi-episode-lifecycle-stress-tests/65-RESEARCH.md
@.planning/phases/65-multi-episode-lifecycle-stress-tests/65-01-SUMMARY.md

# Existing test infrastructure (extend these)
@tests/fixtures/multi_participant.py
@tests/fixtures/game_helpers.py
@tests/fixtures/network_helpers.py
@tests/e2e/test_multi_participant.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend GameOrchestrator for multi-episode scenarios</name>
  <files>tests/fixtures/multi_participant.py</files>
  <action>
Add methods to GameOrchestrator to support multi-episode testing:

1. `wait_for_all_episodes_complete(episode_num: int)` already exists but verify it works for episode_num=2

2. Add `start_single_game_pair(game_idx: int)` method:
   - Extract the per-pair orchestration logic from `start_all_games()` into a reusable method
   - Takes game_idx (0, 1, or 2) and runs that pair through the full startup
   - Used by mixed lifecycle tests that need to start games at different times

3. Add `get_game_completion_status()` method:
   - Returns dict with {game_idx: {"completed": bool, "disconnected": bool, "error": str|None}}
   - Used to track which games completed normally vs failed

4. Ensure proper error handling when a context is closed mid-operation:
   - Methods should catch playwright errors when a context is closed
   - Log the error and mark the game as "disconnected" rather than crashing

The goal is to make the orchestrator robust for lifecycle chaos testing.
  </action>
  <verify>
```bash
# Verify new methods exist
grep -q "def start_single_game_pair" tests/fixtures/multi_participant.py
grep -q "def get_game_completion_status" tests/fixtures/multi_participant.py
```
  </verify>
  <done>GameOrchestrator has start_single_game_pair() and get_game_completion_status() methods</done>
</task>

<task type="auto">
  <name>Task 2: Create lifecycle stress test file</name>
  <files>tests/e2e/test_lifecycle_stress.py</files>
  <action>
Create `tests/e2e/test_lifecycle_stress.py` with comprehensive lifecycle stress tests.

**File structure:**
```python
"""
Lifecycle stress tests for participant scenarios.

Tests validate STRESS-02 through STRESS-07 requirements:
- Multi-episode completion without state corruption
- Mid-game disconnection handling
- Waiting room disconnection isolation
- Focus loss timeout handling
- Mixed lifecycle scenarios

Requires headed mode for WebRTC:
    pytest tests/e2e/test_lifecycle_stress.py --headed
"""
import pytest
import time
from playwright.sync_api import Error as PlaywrightError

from tests.fixtures.multi_participant import GameOrchestrator, get_page_state
from tests.fixtures.game_helpers import (
    run_full_episode_flow_until_gameplay,
    wait_for_episode_complete,
    get_game_state,
    wait_for_socket_connected,
    click_advance_button,
    click_start_button,
    wait_for_game_canvas,
    wait_for_waitroom,
)
from tests.fixtures.network_helpers import set_tab_visibility, wait_for_focus_manager_state
```

**Test 1: test_multi_episode_completion (STRESS-02)**
- Uses `flask_server_multi_episode` fixture (num_episodes=2)
- Uses `multi_participant_contexts` fixture (6 pages, 3 games)
- Start all 3 games via GameOrchestrator
- Wait for episode 1 to complete for all games
- Validate parity for episode 1 (episode_num=0)
- Wait for episode 2 to complete for all games
- Validate parity for episode 2 (episode_num=1)
- Assert all 6 validations pass
- Timeout: 600s (10 min for 2 episodes x 3 games)

**Test 2: test_mid_game_disconnect (STRESS-03)**
- Uses `flask_server` fixture (standard config)
- Uses `player_contexts` fixture (2 pages)
- Start game, wait for gameplay
- Let game run 5 seconds (accumulate frames)
- Close page2's context (`page2.context.close()`)
- Wait for page1 to show partner disconnected state (15s for Socket.IO timeout)
- Verify page1 shows overlay or game state is 'done'
- Timeout: 300s

**Test 3: test_waitroom_disconnect_isolation (STRESS-04)**
- Uses `flask_server` fixture
- Uses `multi_participant_contexts` fixture
- Start Game 1 (pages 0,1) - let it progress to gameplay
- Navigate page 2 to start, enter waitroom, then close its context BEFORE page 3 joins
- Verify Game 1 is still running (unaffected)
- Start Game 2 (pages 4,5) - should match and play normally
- Wait for Game 1 and Game 2 to complete
- Validate parity for both completed games
- Timeout: 600s

**Test 4: test_focus_loss_timeout (STRESS-05)**
- Uses `flask_server_focus_timeout` fixture (timeout_ms=10000)
- Uses `player_contexts` fixture
- Start game, wait for gameplay
- Let game run 3 seconds
- Hide page1's tab via `set_tab_visibility(page1, visible=False)`
- Wait for FocusManager to enter backgrounded state
- Wait 15 seconds (timeout + buffer)
- Verify page1 shows timeout overlay or game ended
- Verify page2 received partner disconnected notification
- Timeout: 300s

**Test 5: test_mixed_lifecycle_scenarios (STRESS-06 + STRESS-07)**
- Uses `flask_server` fixture
- Uses `multi_participant_contexts` fixture
- Game 1 (pages 0,1): Normal completion
- Game 2 (pages 2,3): Mid-game disconnect (close page 3 after 5s)
- Game 3 (pages 4,5): Normal completion with brief focus loss (recover before timeout)
- Start all games with stagger
- Execute chaos scenarios
- Wait for Game 1 and Game 3 to complete normally
- Verify Game 2's page 2 received disconnect notification
- Validate parity for Game 1 and Game 3 (STRESS-07: completed games pass parity)
- Timeout: 600s

**Important patterns from research:**
- Socket.IO ping timeout is ~4s, wait 5-6s after context.close() before checking
- Use `page.wait_for_function()` for state checks rather than polling loops
- Only validate parity for games that completed normally (not disconnected)
- For STRESS-05, verify both players see appropriate end state (timeout initiator vs partner)
  </action>
  <verify>
```bash
# Verify test functions exist
grep -q "def test_multi_episode_completion" tests/e2e/test_lifecycle_stress.py
grep -q "def test_mid_game_disconnect" tests/e2e/test_lifecycle_stress.py
grep -q "def test_waitroom_disconnect_isolation" tests/e2e/test_lifecycle_stress.py
grep -q "def test_focus_loss_timeout" tests/e2e/test_lifecycle_stress.py
grep -q "def test_mixed_lifecycle_scenarios" tests/e2e/test_lifecycle_stress.py
grep -q "STRESS-02" tests/e2e/test_lifecycle_stress.py
grep -q "STRESS-03" tests/e2e/test_lifecycle_stress.py
grep -q "STRESS-04" tests/e2e/test_lifecycle_stress.py
grep -q "STRESS-05" tests/e2e/test_lifecycle_stress.py
grep -q "STRESS-06" tests/e2e/test_lifecycle_stress.py
```
  </verify>
  <done>test_lifecycle_stress.py contains all 5 test functions with proper docstrings and requirement references</done>
</task>

<task type="auto">
  <name>Task 3: Run and verify lifecycle stress tests</name>
  <files></files>
  <action>
Run each stress test individually to verify they pass:

1. **STRESS-02 (multi-episode)**:
```bash
pytest tests/e2e/test_lifecycle_stress.py::test_multi_episode_completion --headed -v -s
```
Expected: All 3 games complete 2 episodes each, all 6 parity validations pass.

2. **STRESS-03 (mid-game disconnect)**:
```bash
pytest tests/e2e/test_lifecycle_stress.py::test_mid_game_disconnect --headed -v -s
```
Expected: Partner sees disconnect overlay, test completes without crash.

3. **STRESS-04 (waitroom disconnect)**:
```bash
pytest tests/e2e/test_lifecycle_stress.py::test_waitroom_disconnect_isolation --headed -v -s
```
Expected: Game 1 and Game 2 complete normally, parity validated.

4. **STRESS-05 (focus loss timeout)**:
```bash
pytest tests/e2e/test_lifecycle_stress.py::test_focus_loss_timeout --headed -v -s
```
Expected: Game ends after timeout, both players see appropriate state.

5. **STRESS-06 (mixed lifecycle)**:
```bash
pytest tests/e2e/test_lifecycle_stress.py::test_mixed_lifecycle_scenarios --headed -v -s
```
Expected: Game 1 and Game 3 complete with parity, Game 2 handled disconnect gracefully.

If any test fails, diagnose and fix the issue. Common issues from research:
- Timing: Increase wait times if Socket.IO ping timeout not respected
- Focus loss: Verify the server config has timeout_ms=10000, not 0
- Multi-episode: Verify server config has num_episodes=2
- Parity: Only validate for games that completed normally
  </action>
  <verify>
```bash
# Run all lifecycle stress tests
pytest tests/e2e/test_lifecycle_stress.py --headed -v
```
All 5 tests should pass.
  </verify>
  <done>All 5 lifecycle stress tests pass consistently</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. All lifecycle stress tests pass:
```bash
pytest tests/e2e/test_lifecycle_stress.py --headed -v
```

2. Test coverage matches requirements:
- STRESS-02: test_multi_episode_completion validates 2+ episodes back-to-back
- STRESS-03: test_mid_game_disconnect validates partner notification and data export
- STRESS-04: test_waitroom_disconnect_isolation validates other participants unaffected
- STRESS-05: test_focus_loss_timeout validates graceful game end after timeout
- STRESS-06: test_mixed_lifecycle_scenarios validates combined scenarios
- STRESS-07: Covered by parity validation in STRESS-02, STRESS-04, and STRESS-06

3. Tests are robust (no flakiness):
```bash
# Run 3 times to check for flaky tests
for i in 1 2 3; do
  echo "=== Run $i ==="
  pytest tests/e2e/test_lifecycle_stress.py --headed -v || exit 1
done
echo "All 3 runs passed"
```
</verification>

<success_criteria>
1. GameOrchestrator extended with start_single_game_pair() and get_game_completion_status()
2. test_lifecycle_stress.py contains 5 test functions
3. All tests reference their STRESS-XX requirement in docstrings
4. test_multi_episode_completion passes (STRESS-02)
5. test_mid_game_disconnect passes (STRESS-03)
6. test_waitroom_disconnect_isolation passes (STRESS-04)
7. test_focus_loss_timeout passes (STRESS-05)
8. test_mixed_lifecycle_scenarios passes (STRESS-06)
9. All completed games' exports validated for exact parity (STRESS-07)
</success_criteria>

<output>
After completion, create `.planning/phases/65-multi-episode-lifecycle-stress-tests/65-02-SUMMARY.md`
</output>
