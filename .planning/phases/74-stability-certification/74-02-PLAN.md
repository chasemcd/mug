---
phase: 74-stability-certification
plan: 02
type: execute
wave: 2
depends_on: ["74-01"]
files_modified: [".planning/phases/74-stability-certification/74-02-SUMMARY.md"]
autonomous: false

must_haves:
  truths:
    - "Full E2E test suite passes 10 consecutive runs with zero failures"
    - "Each run is a fresh pytest invocation (not a single run with --count or rerun)"
    - "Any failure triggers root cause investigation, not retry-and-hope"
    - "All 24 tests pass in every single run"
  artifacts:
    - path: ".planning/phases/74-stability-certification/74-02-SUMMARY.md"
      provides: "Run-by-run results documenting 10 consecutive passes"
  key_links: []
---

<objective>
Execute the full 24-test E2E suite 10 consecutive times, proving zero flakiness. Each run is a fresh pytest invocation. Any failure triggers immediate root cause investigation and fix -- never retry-and-hope.

Purpose: STAB-01 requires 10 consecutive full-suite passes to certify stability. This is the capstone phase proving the entire v1.17 E2E Test Reliability milestone is complete.
Output: A documented record of 10 consecutive passing runs with timing data, or a root cause analysis and fix for any failure encountered.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/74-stability-certification/74-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Execute 10 consecutive full E2E suite runs</name>
  <files>
    tests/e2e/test_infrastructure.py
    tests/e2e/test_multiplayer_basic.py
    tests/e2e/test_data_comparison.py
    tests/e2e/test_focus_loss_data_parity.py
    tests/e2e/test_latency_injection.py
    tests/e2e/test_network_disruption.py
    tests/e2e/test_lifecycle_stress.py
    tests/e2e/test_multi_participant.py
  </files>
  <action>
    Execute the full E2E test suite 10 consecutive times. Each run MUST be a separate, fresh pytest invocation.

    **The exact command for each run:**
    ```bash
    python -m pytest tests/e2e/ --browser chromium -v --tb=short --timeout=600 2>&1
    ```

    **Important execution details:**
    - The e2e conftest.py automatically forces `--headed` mode (no need to pass it)
    - Each run covers all 24 tests across 8 modules
    - Each run takes approximately 10-15 minutes
    - Total expected time: 100-150 minutes (1.5-2.5 hours)
    - Use `--timeout=600` (10 minutes per test) as a safety net for hung tests
    - Run from the repository root directory: `/Users/chasemcd/Repositories/interactive-gym`

    **For each run, record:**
    1. Run number (1-10)
    2. Start time
    3. End time / duration
    4. Result: PASSED (24/24) or FAILED (which tests failed)
    5. Any warnings or unusual output

    **Tracking format (build this as you go):**
    ```
    | Run | Start | Duration | Result | Notes |
    |-----|-------|----------|--------|-------|
    | 1   | HH:MM | XXXs     | 24/24 PASSED | - |
    | 2   | HH:MM | XXXs     | 24/24 PASSED | - |
    ...
    ```

    **ON FAILURE -- CRITICAL PROTOCOL:**
    If ANY test fails during ANY run:

    1. STOP the 10-run sequence immediately
    2. Record which test(s) failed and the full error output
    3. Investigate root cause:
       - Read the test failure traceback carefully
       - Check if it is a test issue or a product code issue
       - Check if it is an environmental issue (port conflict, stale process)
       - Run the failed test in isolation to see if it reproduces
       - If it reproduces in isolation: this is a real bug -- diagnose and fix
       - If it does NOT reproduce in isolation: this is a test ordering / state leak issue -- diagnose and fix
    4. After fixing the root cause, RESTART the 10-run count from 1
       - Partial counts do not carry over
       - The requirement is 10 CONSECUTIVE passes, not 10 total passes
    5. Document the failure, root cause, and fix in the summary

    **DO NOT:**
    - Re-run a failed test hoping it passes ("retry-and-hope")
    - Skip the failed test
    - Add xfail or skip markers to make it pass
    - Reduce assertion strictness
    - Continue the count after a failure

    **Success condition:**
    Runs 1 through 10 all show "24 passed" with zero failures. The 10th consecutive passing run completes the STAB-01 requirement.
  </action>
  <verify>
    The final run (Run 10) output contains "24 passed" and no "failed" or "error" results. The tracking table shows 10 consecutive rows with "24/24 PASSED" and no gaps.
  </verify>
  <done>
    10 consecutive full E2E suite runs completed with 24/24 tests passing in every run. Zero failures across all 240 test executions (24 tests x 10 runs). STAB-01 satisfied.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
    Executed the full 24-test E2E suite 10 consecutive times. Each run was a fresh pytest invocation. The run-by-run results table documents every run's outcome.
  </what-built>
  <how-to-verify>
    1. Review the run results table in the summary output
    2. Confirm all 10 runs show 24/24 PASSED
    3. Confirm no failures were silently skipped or retried
    4. If any failures occurred and were fixed, review the root cause analysis
    5. Optionally run one more full suite pass yourself to verify:
       ```
       python -m pytest tests/e2e/ --browser chromium -v --tb=short --timeout=600
       ```
       Expected: 24 passed, 0 failed
  </how-to-verify>
  <resume-signal>Type "approved" to certify stability, or describe any concerns</resume-signal>
</task>

</tasks>

<verification>
- 10 consecutive runs completed, each showing "24 passed"
- Zero failures across all 240 individual test executions
- No xfail/skip markers added during the process
- No tolerance values changed during the process
- Any failures that occurred were properly investigated (root cause documented)
- STAB-01 requirement satisfied
</verification>

<success_criteria>
The full E2E test suite has been proven stable: 10 consecutive runs, 24 tests each, zero failures, zero flaky markers. The v1.17 E2E Test Reliability milestone is complete. STAB-01 and STAB-02 are both satisfied.
</success_criteria>

<output>
After completion, create `.planning/phases/74-stability-certification/74-02-SUMMARY.md`
</output>
