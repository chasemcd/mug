---
phase: 63-parity-test-stabilization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - interactive_gym/examples/cogrid/overcooked_human_human_multiplayer_test.py
  - tests/e2e/test_network_disruption.py
  - tests/e2e/test_latency_injection.py
autonomous: true

must_haves:
  truths:
    - "test_active_input_with_latency[chromium-100] passes 10 consecutive runs"
    - "test_active_input_with_packet_loss passes 10 consecutive runs"
    - "No tolerance or xfail markers needed for parity tests"
  artifacts:
    - path: "interactive_gym/examples/cogrid/overcooked_human_human_multiplayer_test.py"
      provides: "Test configuration with higher confirmation timeout"
      contains: "input_confirmation_timeout_ms"
    - path: "tests/e2e/test_network_disruption.py"
      provides: "Clean test without flaky warnings"
      min_lines: 350
    - path: "tests/e2e/test_latency_injection.py"
      provides: "Clean test without flaky warnings"
      min_lines: 380
  key_links:
    - from: "overcooked_human_human_multiplayer_test.py"
      to: "pyodide_multiplayer_game.js"
      via: "scene_metadata.input_confirmation_timeout_ms"
      pattern: "input_confirmation_timeout_ms"
---

<objective>
Stabilize E2E parity tests for CI reliability by increasing input confirmation timeout and cleaning up flaky test documentation

Purpose: Tests must pass consistently (10+ runs) without tolerance or xfail markers for CI integration
Output: Stable test suite with updated timeout configuration and clean docstrings
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/63-parity-test-stabilization/63-RESEARCH.md
@.planning/phases/61-input-confirmation-protocol/61-01-SUMMARY.md
@.planning/phases/62-data-parity-validation/62-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Increase input confirmation timeout in test configuration</name>
  <files>interactive_gym/examples/cogrid/overcooked_human_human_multiplayer_test.py</files>
  <action>
Add `input_confirmation_timeout_ms=1500` to the pyodide() chain on the cramped_room_human_human scene.

The scene configuration currently chains: `.gameplay()`, `.matchmaking()`, `.focus_loss_config()`.

Add `.pyodide(input_confirmation_timeout_ms=1500)` after focus_loss_config() to override the default 500ms timeout. This gives more time for packet redundancy under 15% packet loss.

Why 1500ms:
- 500ms proved mostly sufficient (Phase 62) but flaky under worst-case packet loss
- 1500ms gives 3x headroom for final-frame inputs which have limited redundancy
- This is test-only config; production uses the default 500ms which is fine for typical conditions

Implementation:
```python
(
    oc_scenes.cramped_room_human_human
    .gameplay(num_episodes=1, max_steps=450)
    .matchmaking(max_rtt=None)
    .focus_loss_config(timeout_ms=0, pause_on_partner_background=False)
    .pyodide(input_confirmation_timeout_ms=1500)  # Higher timeout for packet loss tests
),
```

Also update the file header docstring to mention the increased timeout.
  </action>
  <verify>
Run: `python -c "from interactive_gym.examples.cogrid.scenes import scenes; print(scenes.cramped_room_human_human.input_confirmation_timeout_ms)"`
Should still show 500 (base scene unchanged)

Then check test config imports and applies the override:
`grep -n "input_confirmation_timeout_ms" interactive_gym/examples/cogrid/overcooked_human_human_multiplayer_test.py`
Should show the new parameter in the scene configuration.
  </verify>
  <done>Test configuration has 1500ms input confirmation timeout for packet loss resilience</done>
</task>

<task type="auto">
  <name>Task 2: Clean up test docstrings (remove flaky warnings)</name>
  <files>tests/e2e/test_network_disruption.py, tests/e2e/test_latency_injection.py</files>
  <action>
Remove the "Known flaky tests" sections from both test file module docstrings.

Phase 61 implemented the input confirmation protocol that addresses the root cause (force-promoting unconfirmed speculative data at episode end). With the increased timeout in Task 1, these tests are no longer flaky.

**In test_network_disruption.py:**
Remove lines 17-23 (the "Known flaky tests" paragraph) from the module docstring.

**In test_latency_injection.py:**
Remove lines 24-32 (the "Known flaky tests" paragraph) from the module docstring.

Also update any inline comments in the test functions that reference flakiness or known bugs - these are now fixed.
  </action>
  <verify>
Run: `grep -n "Known flaky" tests/e2e/test_network_disruption.py tests/e2e/test_latency_injection.py`
Should return no matches.

Run: `grep -n "force-promotes" tests/e2e/test_network_disruption.py tests/e2e/test_latency_injection.py`
Should return no matches (this was part of the flaky warning).
  </verify>
  <done>Test docstrings cleaned up, no flaky warnings remain</done>
</task>

<task type="auto">
  <name>Task 3: Verify test stability with 10 consecutive runs</name>
  <files></files>
  <action>
Run each test 10 times to verify stability. Use pytest-repeat if available, otherwise run in a loop.

**Test 1: test_active_input_with_latency[chromium-100]**
```bash
cd /Users/chasemcd/Repositories/interactive-gym
for i in {1..10}; do
    echo "=== Run $i ==="
    pytest tests/e2e/test_latency_injection.py::test_active_input_with_latency[chromium-100] -v --timeout=300
    if [ $? -ne 0 ]; then
        echo "FAILED on run $i"
        exit 1
    fi
done
echo "All 10 runs passed!"
```

**Test 2: test_active_input_with_packet_loss**
```bash
cd /Users/chasemcd/Repositories/interactive-gym
for i in {1..10}; do
    echo "=== Run $i ==="
    pytest tests/e2e/test_network_disruption.py::test_active_input_with_packet_loss -v --timeout=300
    if [ $? -ne 0 ]; then
        echo "FAILED on run $i"
        exit 1
    fi
done
echo "All 10 runs passed!"
```

If pytest-repeat is available, can use:
```bash
pytest tests/e2e/test_latency_injection.py::test_active_input_with_latency[chromium-100] --count=10 -v
pytest tests/e2e/test_network_disruption.py::test_active_input_with_packet_loss --count=10 -v
```

Note: Each test takes 2-3 minutes, so 10 runs = 20-30 minutes per test.
  </action>
  <verify>
Both tests pass all 10 consecutive runs with exit code 0.

If any run fails, examine the output:
1. Check if it's still a parity divergence (may need even higher timeout)
2. Check if it's a different failure (timeout, connection, etc.)
3. Report findings if adjustments needed
  </verify>
  <done>Both tests pass 10 consecutive runs with no failures</done>
</task>

</tasks>

<verification>
Phase verification (after all tasks):
1. `grep "input_confirmation_timeout_ms" interactive_gym/examples/cogrid/overcooked_human_human_multiplayer_test.py` shows 1500
2. `grep "Known flaky" tests/e2e/` returns no matches
3. Test run logs show 10/10 passes for both critical tests
</verification>

<success_criteria>
- [ ] Test config has input_confirmation_timeout_ms=1500
- [ ] No "Known flaky" warnings in test docstrings
- [ ] test_active_input_with_latency[chromium-100] passes 10 consecutive runs
- [ ] test_active_input_with_packet_loss passes 10 consecutive runs
- [ ] PARITY-06 and PARITY-07 requirements satisfied
</success_criteria>

<output>
After completion, create `.planning/phases/63-parity-test-stabilization/63-01-SUMMARY.md`
</output>
