---
phase: 70-validation-and-cleanup
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/e2e/test_worker_validation.py
autonomous: false

must_haves:
  truths:
    - "Step latency with Worker is not degraded compared to direct Pyodide baseline"
    - "No memory growth observed across multiple consecutive game sessions"
  artifacts:
    - path: "tests/e2e/test_worker_validation.py"
      provides: "Step latency measurement test and memory growth test"
      contains: "test_step_latency_not_degraded"
  key_links:
    - from: "tests/e2e/test_worker_validation.py"
      to: "interactive_gym/server/static/js/pyodide_remote_game.js"
      via: "page.evaluate reading pipelineMetrics"
      pattern: "pipelineMetrics"
---

<objective>
Validate that the Pyodide Web Worker migration does not degrade game loop step latency (VALID-03) and does not introduce memory leaks across game sessions (VALID-04).

Purpose: Moving Pyodide to a Worker adds a postMessage round-trip to every step() and reset() call. This plan measures whether that overhead is acceptable and whether Worker lifecycle management properly releases memory.

Output: Automated latency measurement test, manual memory verification via browser Performance tab.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@interactive_gym/server/static/js/pyodide_remote_game.js
@interactive_gym/server/static/js/PyodideWorker.js
@tests/e2e/test_multiplayer_basic.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create step latency measurement test</name>
  <files>tests/e2e/test_worker_validation.py</files>
  <action>
    Create `tests/e2e/test_worker_validation.py` with two tests:

    **Test 1: test_step_latency_not_degraded**

    This test measures the step() round-trip time during a multiplayer game. The game already has pipeline metrics instrumentation (Phase 28) that tracks `stepCallTimestamp` and `stepReturnTimestamp` on every frame.

    Implementation:
    1. Use `flask_server` and `player_contexts` fixtures (same as test_multiplayer_basic.py)
    2. Connect two players, navigate through instructions, start matchmaking
    3. Wait for game canvas and game objects
    4. Set tab visibility for both players
    5. Wait for 100 frames of gameplay to accumulate (gives stable measurement)
    6. Read step latency from the game's pipeline metrics via page.evaluate:
       ```javascript
       () => {
           const game = window.game;
           if (!game || !game.pipelineMetrics) return null;
           // Measure step latency over recent frames
           // The game logs [LATENCY] step_ms values to console
           // But we can measure directly: stepReturnTimestamp - stepCallTimestamp
           return {
               stepCallTimestamp: game.pipelineMetrics.stepCallTimestamp,
               stepReturnTimestamp: game.pipelineMetrics.stepReturnTimestamp,
               lastStepMs: game.pipelineMetrics.stepReturnTimestamp - game.pipelineMetrics.stepCallTimestamp,
               frameNumber: game.frameNumber,
           };
       }
       ```
    7. Sample step latency at 10 points during the game (every 50ms for 500ms) to get a distribution
    8. Assert median step latency < 50ms (generous threshold; Worker postMessage round-trip should be < 5ms, Pyodide step itself is ~10-20ms for Overcooked)
    9. Log the latency distribution for the record

    The baseline for comparison: direct Pyodide step() was ~10-20ms for the Overcooked environment. Worker adds ~1-5ms overhead for postMessage serialization. So total should be < 30ms typically, with 50ms as a conservative threshold that still catches regressions.

    **Test 2: test_no_memory_growth_across_sessions**

    This test runs multiple game sessions sequentially to check for memory leaks.

    Implementation:
    1. Use `flask_server_fresh` fixture (fresh server per test) and a browser fixture
    2. For 3 consecutive iterations:
       a. Create two fresh browser contexts
       b. Run both players through the full flow: navigate -> advance -> start -> wait for game -> wait for episode complete
       c. After episode completes, capture JS heap size via Performance API:
          ```javascript
          () => {
              if (performance.memory) {
                  return {
                      usedJSHeapSize: performance.memory.usedJSHeapSize,
                      totalJSHeapSize: performance.memory.totalJSHeapSize,
                  };
              }
              return null;
          }
          ```
       d. Close browser contexts (triggers Worker.destroy())
       e. Log heap sizes
    3. Compare heap sizes across iterations. Assert that iteration 3 heap is not more than 2x iteration 1 heap (generous threshold -- real memory leaks show unbounded growth, not 2x).

    Note: `performance.memory` is Chrome-only and may not be available in all Playwright configurations. If it returns null, log a warning and skip the assertion (the test still validates that 3 consecutive sessions complete without crashes, which is a basic memory stability check).

    Important notes:
    - Both tests require `--headed` for WebRTC
    - Import patterns follow existing tests (test_multiplayer_basic.py)
    - Use `@pytest.mark.timeout(300)` for latency test, `@pytest.mark.timeout(900)` for memory test (3 sessions)
    - Add module docstring explaining these are Worker migration validation tests for VALID-03 and VALID-04
  </action>
  <verify>
    File exists and has correct structure:
    ```
    python -c "import ast; ast.parse(open('tests/e2e/test_worker_validation.py').read()); print('Syntax OK')"
    ```
    Test file contains both test functions:
    ```
    grep -n "def test_" tests/e2e/test_worker_validation.py
    ```
    Should show test_step_latency_not_degraded and test_no_memory_growth_across_sessions.
  </verify>
  <done>
    test_worker_validation.py created with test_step_latency_not_degraded (VALID-03) and test_no_memory_growth_across_sessions (VALID-04) tests.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run latency and memory tests</name>
  <files>tests/e2e/test_worker_validation.py</files>
  <action>
    Run the step latency test:
    ```bash
    cd /Users/chasemcd/Repositories/interactive-gym
    PWHEADED=1 python -m pytest tests/e2e/test_worker_validation.py::test_step_latency_not_degraded -v --timeout=300 2>&1
    ```

    Capture the output. Look for:
    - Median step latency value (should be < 50ms)
    - The latency distribution log

    Then run the memory test:
    ```bash
    PWHEADED=1 python -m pytest tests/e2e/test_worker_validation.py::test_no_memory_growth_across_sessions -v --timeout=900 2>&1
    ```

    Capture the output. Look for:
    - Heap sizes for each iteration
    - Whether the assertion passed (no 2x growth)
    - If performance.memory was unavailable, note the warning

    If either test fails, debug and fix the test code. Common issues:
    - Timing: may need longer waits for frames to accumulate
    - performance.memory not available: make the assertion conditional
    - Pipeline metrics structure may have changed: check the actual game object fields

    IMPORTANT: These tests require headed mode. Use PWHEADED=1.
  </action>
  <verify>
    Both tests pass:
    ```
    test_step_latency_not_degraded PASSED
    test_no_memory_growth_across_sessions PASSED
    ```
    Latency output shows median step time < 50ms.
    Memory output shows no 2x growth across 3 sessions (or skip message if performance.memory unavailable).
  </verify>
  <done>
    Step latency test confirms Worker postMessage overhead is acceptable (VALID-03). Memory test confirms no unbounded growth across 3 consecutive game sessions (VALID-04).
  </done>
</task>

<task type="checkpoint:human-verify" gate="non-blocking">
  <what-built>
    Automated step latency measurement and memory growth detection tests for the Pyodide Worker migration.

    VALID-03: Step latency measurement compares Worker round-trip time against a 50ms threshold (baseline was 10-20ms direct, Worker adds 1-5ms overhead).

    VALID-04: Memory growth test runs 3 consecutive game sessions and checks JS heap size doesn't grow unboundedly.
  </what-built>
  <how-to-verify>
    If you want to independently verify memory with browser DevTools:

    1. Start the test server: `python -m interactive_gym.examples.cogrid.overcooked_human_human_multiplayer_test --port 5700`
    2. Open Chrome to http://localhost:5700
    3. Open DevTools -> Performance tab
    4. Click "Record" before starting a game
    5. Play through one episode (it auto-completes via timeout)
    6. Stop recording, check the Memory chart
    7. Repeat for 2-3 more games
    8. Check that JS Heap doesn't trend upward across games

    This manual step is optional -- the automated test covers the programmatic check.
  </how-to-verify>
  <resume-signal>Type "approved" or describe any memory concerns observed</resume-signal>
</task>

</tasks>

<verification>
1. tests/e2e/test_worker_validation.py exists with both test functions
2. test_step_latency_not_degraded passes with median < 50ms
3. test_no_memory_growth_across_sessions passes (or skips gracefully if performance.memory unavailable)
4. No crashes or Worker-related errors in test output
</verification>

<success_criteria>
- Step latency with Worker is within acceptable range (< 50ms median, vs ~10-20ms baseline)
- 3 consecutive game sessions complete without memory growth
- VALID-03 satisfied: Step latency not degraded
- VALID-04 satisfied: No memory leaks across sessions
</success_criteria>

<output>
After completion, create `.planning/phases/70-validation-and-cleanup/70-02-SUMMARY.md`
</output>
