---
phase: 70-validation-and-cleanup
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/e2e/test_worker_validation.py
autonomous: false

must_haves:
  truths:
    - "Step latency with Worker is not degraded compared to direct Pyodide baseline"
    - "No memory growth observed across 10 consecutive game sessions"
  artifacts:
    - path: "tests/e2e/test_worker_validation.py"
      provides: "Step latency measurement test and memory growth test"
      contains: "test_step_latency_not_degraded"
    - path: "tests/e2e/test_worker_validation.py"
      provides: "Memory growth test across 10 sessions"
      contains: "test_no_memory_growth_across_sessions"
  key_links:
    - from: "tests/e2e/test_worker_validation.py"
      to: "interactive_gym/server/static/js/pyodide_multiplayer_game.js"
      via: "page.evaluate reading pipelineMetrics on multiplayer game"
      pattern: "pipelineMetrics"
    - from: "tests/e2e/test_worker_validation.py"
      to: "interactive_gym/server/static/js/PyodideWorker.js"
      via: "Worker lifecycle (init/destroy) across 10 sessions"
      pattern: "usedJSHeapSize"
---

<objective>
Validate that the Pyodide Web Worker migration does not degrade game loop step latency (VALID-03) and does not introduce memory leaks across game sessions (VALID-04).

Purpose: Moving Pyodide to a Worker adds a postMessage round-trip to every step() and reset() call. This plan measures whether that overhead is acceptable and whether Worker lifecycle management properly releases memory.

Output: Automated latency measurement test, automated memory growth test across 10 consecutive sessions, manual memory verification via browser Performance tab.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@interactive_gym/server/static/js/pyodide_multiplayer_game.js
@interactive_gym/server/static/js/PyodideWorker.js
@tests/e2e/test_multiplayer_basic.py
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create step latency measurement test</name>
  <files>tests/e2e/test_worker_validation.py</files>
  <action>
    Create `tests/e2e/test_worker_validation.py` with the step latency test.

    Add a module docstring explaining these are Worker migration validation tests for VALID-03 and VALID-04.

    **Test: test_step_latency_not_degraded**

    This test measures the step() round-trip time during a multiplayer game. The game already has pipeline metrics instrumentation (Phase 28) that tracks `stepCallTimestamp` and `stepReturnTimestamp` on every frame.

    Implementation:
    1. Use `flask_server` and `player_contexts` fixtures (same as test_multiplayer_basic.py)
    2. Connect two players, navigate through instructions, start matchmaking
    3. Wait for game canvas and game objects
    4. Set tab visibility for both players
    5. Wait for 100 frames of gameplay to accumulate (gives stable measurement)
    6. Read step latency from the game's pipeline metrics via page.evaluate:
       ```javascript
       () => {
           const game = window.game;
           if (!game || !game.pipelineMetrics) return null;
           return {
               stepCallTimestamp: game.pipelineMetrics.stepCallTimestamp,
               stepReturnTimestamp: game.pipelineMetrics.stepReturnTimestamp,
               lastStepMs: game.pipelineMetrics.stepReturnTimestamp - game.pipelineMetrics.stepCallTimestamp,
               frameNumber: game.frameNumber,
           };
       }
       ```
    7. Sample step latency at 10 points during the game (every 50ms for 500ms) to get a distribution
    8. Assert median step latency < 50ms (generous threshold; Worker postMessage round-trip should be < 5ms, Pyodide step itself is ~10-20ms for Overcooked)
    9. Log the latency distribution for the record

    The baseline for comparison: direct Pyodide step() was ~10-20ms for the Overcooked environment. Worker adds ~1-5ms overhead for postMessage serialization. So total should be < 30ms typically, with 50ms as a conservative threshold that still catches regressions.

    Important notes:
    - Test requires `--headed` for WebRTC
    - Import patterns follow existing tests (test_multiplayer_basic.py)
    - Use `@pytest.mark.timeout(300)` for the latency test
  </action>
  <verify>
    File exists and has correct structure:
    ```
    python -c "import ast; ast.parse(open('tests/e2e/test_worker_validation.py').read()); print('Syntax OK')"
    ```
    Test file contains the latency test function:
    ```
    grep -n "def test_step_latency_not_degraded" tests/e2e/test_worker_validation.py
    ```
  </verify>
  <done>
    test_worker_validation.py created with test_step_latency_not_degraded (VALID-03).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add memory growth test across 10 consecutive sessions</name>
  <files>tests/e2e/test_worker_validation.py</files>
  <action>
    Add the memory growth test to the existing `tests/e2e/test_worker_validation.py` file created in Task 1.

    **Test: test_no_memory_growth_across_sessions**

    This test runs 10 consecutive game sessions sequentially to check for memory leaks. The ROADMAP requires "10 consecutive games show no memory growth" (VALID-04).

    Implementation:
    1. Use `flask_server_fresh` fixture (fresh server per test) and a browser fixture
    2. For 10 consecutive iterations:
       a. Create two fresh browser contexts
       b. Run both players through the full flow: navigate -> advance -> start -> wait for game -> wait for episode complete
       c. After episode completes, capture JS heap size via Performance API:
          ```javascript
          () => {
              if (performance.memory) {
                  return {
                      usedJSHeapSize: performance.memory.usedJSHeapSize,
                      totalJSHeapSize: performance.memory.totalJSHeapSize,
                  };
              }
              return null;
          }
          ```
       d. Close browser contexts (triggers Worker.destroy())
       e. Log heap sizes for each iteration
    3. Compare heap sizes across iterations. Assert that iteration 10 heap is not more than 2x iteration 1 heap (generous threshold -- real memory leaks show unbounded growth, not 2x).

    Note: `performance.memory` is Chrome-only and may not be available in all Playwright configurations. If it returns null, log a warning and skip the assertion (the test still validates that 10 consecutive sessions complete without crashes, which is a basic memory stability check).

    Important notes:
    - Test requires `--headed` for WebRTC
    - Use `@pytest.mark.timeout(3000)` for the memory test (10 sessions, each taking ~2-3 minutes)
    - Import patterns follow existing tests (test_multiplayer_basic.py)
  </action>
  <verify>
    Test file contains both test functions:
    ```
    grep -n "def test_" tests/e2e/test_worker_validation.py
    ```
    Should show test_step_latency_not_degraded and test_no_memory_growth_across_sessions.

    Verify the memory test has 10 iterations:
    ```
    grep -n "range(10)" tests/e2e/test_worker_validation.py
    ```
    Should show the 10-iteration loop.

    Verify timeout is set correctly:
    ```
    grep -n "timeout(3000)" tests/e2e/test_worker_validation.py
    ```
  </verify>
  <done>
    test_no_memory_growth_across_sessions added to test_worker_validation.py with 10 consecutive sessions (matching ROADMAP VALID-04 requirement), 3000s timeout, and 2x heap growth threshold.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run latency and memory tests</name>
  <files>tests/e2e/test_worker_validation.py</files>
  <action>
    Run the step latency test:
    ```bash
    cd /Users/chasemcd/Repositories/interactive-gym
    PWHEADED=1 python -m pytest tests/e2e/test_worker_validation.py::test_step_latency_not_degraded -v --timeout=300 2>&1
    ```

    Capture the output. Look for:
    - Median step latency value (should be < 50ms)
    - The latency distribution log

    Then run the memory test:
    ```bash
    PWHEADED=1 python -m pytest tests/e2e/test_worker_validation.py::test_no_memory_growth_across_sessions -v --timeout=3000 2>&1
    ```

    Capture the output. Look for:
    - Heap sizes for each of the 10 iterations
    - Whether the assertion passed (no 2x growth between iteration 1 and iteration 10)
    - If performance.memory was unavailable, note the warning

    If either test fails, debug and fix the test code. Common issues:
    - Timing: may need longer waits for frames to accumulate
    - performance.memory not available: make the assertion conditional
    - Pipeline metrics structure may have changed: check the actual game object fields

    IMPORTANT: These tests require headed mode. Use PWHEADED=1.
    IMPORTANT: The memory test runs 10 consecutive sessions and may take 20-30 minutes.
  </action>
  <verify>
    Both tests pass:
    ```
    test_step_latency_not_degraded PASSED
    test_no_memory_growth_across_sessions PASSED
    ```
    Latency output shows median step time < 50ms.
    Memory output shows no 2x growth across 10 sessions (or skip message if performance.memory unavailable).
  </verify>
  <done>
    Step latency test confirms Worker postMessage overhead is acceptable (VALID-03). Memory test confirms no unbounded growth across 10 consecutive game sessions (VALID-04).
  </done>
</task>

<task type="checkpoint:human-verify" gate="non-blocking">
  <what-built>
    Automated step latency measurement and memory growth detection tests for the Pyodide Worker migration.

    VALID-03: Step latency measurement compares Worker round-trip time against a 50ms threshold (baseline was 10-20ms direct, Worker adds 1-5ms overhead).

    VALID-04: Memory growth test runs 10 consecutive game sessions and checks JS heap size doesn't grow unboundedly (matching ROADMAP requirement of "10 consecutive games show no memory growth").
  </what-built>
  <how-to-verify>
    If you want to independently verify memory with browser DevTools:

    1. Start the test server: `python -m interactive_gym.examples.cogrid.overcooked_human_human_multiplayer_test --port 5700`
    2. Open Chrome to http://localhost:5700
    3. Open DevTools -> Performance tab
    4. Click "Record" before starting a game
    5. Play through one episode (it auto-completes via timeout)
    6. Stop recording, check the Memory chart
    7. Repeat for 2-3 more games
    8. Check that JS Heap doesn't trend upward across games

    This manual step is optional -- the automated test covers the programmatic check.
  </how-to-verify>
  <resume-signal>Type "approved" or describe any memory concerns observed</resume-signal>
</task>

</tasks>

<verification>
1. tests/e2e/test_worker_validation.py exists with both test functions
2. test_step_latency_not_degraded passes with median < 50ms
3. test_no_memory_growth_across_sessions passes with 10 consecutive sessions (or skips gracefully if performance.memory unavailable)
4. No crashes or Worker-related errors in test output
</verification>

<success_criteria>
- Step latency with Worker is within acceptable range (< 50ms median, vs ~10-20ms baseline)
- 10 consecutive game sessions complete without memory growth (ROADMAP requirement)
- VALID-03 satisfied: Step latency not degraded
- VALID-04 satisfied: No memory leaks across sessions
</success_criteria>

<output>
After completion, create `.planning/phases/70-validation-and-cleanup/70-02-SUMMARY.md`
</output>
